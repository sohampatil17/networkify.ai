{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "djJR4hmAkr7i",
        "outputId": "2a56cbfa-5875-44f7-fd98-9edacb03aa5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nx-arangodb\n",
            "  Downloading nx_arangodb-1.3.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting networkx<=3.4,>=3.0 (from nx-arangodb)\n",
            "  Downloading networkx-3.4-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting phenolrs~=0.5 (from nx-arangodb)\n",
            "  Downloading phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting python-arango~=8.1 (from nx-arangodb)\n",
            "  Downloading python_arango-8.1.6-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting adbnx-adapter~=5.0.5 (from nx-arangodb)\n",
            "  Downloading adbnx_adapter-5.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (2.32.3)\n",
            "Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (13.9.4)\n",
            "Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (75.1.0)\n",
            "Requirement already satisfied: numpy~=1.26 in /usr/local/lib/python3.11/dist-packages (from phenolrs~=0.5->nx-arangodb) (1.26.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.3.0)\n",
            "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (1.0.0)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.10.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (8.6.1)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (24.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.7.1->python-arango~=8.1->nx-arangodb) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (0.1.2)\n",
            "Downloading nx_arangodb-1.3.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adbnx_adapter-5.0.6-py3-none-any.whl (21 kB)\n",
            "Downloading networkx-3.4-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading phenolrs-0.5.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_arango-8.1.6-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: networkx, python-arango, phenolrs, adbnx-adapter, nx-arangodb\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adbnx-adapter-5.0.6 networkx-3.4 nx-arangodb-1.3.0 phenolrs-0.5.9 python-arango-8.1.6\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.5-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.41 (from langchain)\n",
            "  Downloading langchain_core-0.3.43-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.18-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.55-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.8-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.3.5-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.43-py3-none-any.whl (415 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.18-py3-none-any.whl (39 kB)\n",
            "Downloading langgraph_prebuilt-0.1.2-py3-none-any.whl (24 kB)\n",
            "Downloading langgraph_sdk-0.1.55-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, pydantic-settings, langgraph-sdk, dataclasses-json, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langchain, langgraph, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.40\n",
            "    Uninstalling langchain-core-0.3.40:\n",
            "      Successfully uninstalled langchain-core-0.3.40\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.19\n",
            "    Uninstalling langchain-0.3.19:\n",
            "      Successfully uninstalled langchain-0.3.19\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.20 langchain-community-0.3.19 langchain-core-0.3.43 langchain-openai-0.3.8 langgraph-0.3.5 langgraph-checkpoint-2.0.18 langgraph-prebuilt-0.1.2 langgraph-sdk-0.1.55 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 tiktoken-0.9.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.20.1-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.20.1 gradio-client-1.7.2 groovy-0.1.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.10 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install nx-arangodb\n",
        "!pip install --upgrade langchain langchain-community langchain-openai langgraph\n",
        "!pip install pandas matplotlib networkx\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5SLt-mPk3pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57eef085-4832-49d2-fff9-d270a83263c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[06:26:46 +0000] [INFO]: NetworkX-cuGraph is available.\n",
            "INFO:nx_arangodb:NetworkX-cuGraph is available.\n"
          ]
        }
      ],
      "source": [
        "# Import the required modules\n",
        "import networkx as nx\n",
        "import nx_arangodb as nxadb\n",
        "from arango import ArangoClient\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV_0tanuu9os",
        "outputId": "647a24f1-a0fa-4687-a1e0-d403f6350ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 10 06:26:53 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com # Requires CUDA-capable GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdYPwGjevEyx",
        "outputId": "1f98c7e6-dc27-43b1-fc27-5664192c388b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: nx-cugraph-cu12 in /usr/local/lib/python3.11/dist-packages (25.2.0)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (13.3.0)\n",
            "Requirement already satisfied: networkx>=3.2 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (3.4)\n",
            "Requirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (1.26.4)\n",
            "Requirement already satisfied: pylibcugraph-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from nx-cugraph-cu12) (25.2.0)\n",
            "Requirement already satisfied: libcugraph-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n",
            "Requirement already satisfied: pylibraft-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n",
            "Requirement already satisfied: rmm-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n",
            "Requirement already satisfied: libraft-cu12==25.2.* in /usr/local/lib/python3.11/dist-packages (from libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (25.2.0)\n",
            "Requirement already satisfied: cuda-python<13.0a0,>=12.6.2 in /usr/local/lib/python3.11/dist-packages (from pylibraft-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.6.2.post1)\n",
            "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.5.3.2)\n",
            "Requirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (10.3.6.82)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (11.6.3.83)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.11/dist-packages (from libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.5.1.3)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x>=12.0.0->nx-cugraph-cu12) (0.8.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12->libraft-cu12==25.2.*->libcugraph-cu12==25.2.*->pylibcugraph-cu12==25.2.*->nx-cugraph-cu12) (12.5.82)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WAqzvU9lAoV"
      },
      "outputs": [],
      "source": [
        "# Set OpenAI API key directly\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"xxx\" # use ur api key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process LinkedIn connections file\n",
        "def process_connections_file(file_path, owner_name, id_offset=0):\n",
        "    # Load the connections data\n",
        "    connections_df = pd.read_csv(file_path)\n",
        "\n",
        "    # Create a unique identifier for each connection\n",
        "    connections_df['id'] = connections_df.index + id_offset\n",
        "    connections_df['full_name'] = connections_df['First Name'] + ' ' + connections_df['Last Name']\n",
        "    connections_df['owner'] = owner_name  # Add owner information\n",
        "\n",
        "    # Select relevant columns - adjust these based on your actual CSV structure\n",
        "    clean_df = connections_df[['id', 'full_name', 'Company', 'Position', 'Email Address', 'owner']]\n",
        "\n",
        "    # Handle missing values\n",
        "    clean_df = clean_df.fillna({'Company': 'Unknown', 'Position': 'Unknown', 'Email Address': ''})\n",
        "\n",
        "    return clean_df\n",
        "\n",
        "# Function to generate random skills based on job titles\n",
        "def generate_random_skills(df):\n",
        "    # Define skill pools by industry/role\n",
        "    tech_skills = [\n",
        "        \"Python\", \"JavaScript\", \"SQL\", \"Java\", \"C++\", \"AWS\", \"Azure\",\n",
        "        \"Docker\", \"Kubernetes\", \"Machine Learning\", \"Data Science\",\n",
        "        \"React\", \"Node.js\", \"Cloud Computing\", \"DevOps\", \"Cybersecurity\",\n",
        "        \"Artificial Intelligence\", \"Blockchain\", \"Big Data\", \"Data Analysis\"\n",
        "    ]\n",
        "\n",
        "    business_skills = [\n",
        "        \"Project Management\", \"Strategic Planning\", \"Business Development\",\n",
        "        \"Marketing\", \"Sales\", \"Leadership\", \"Negotiation\", \"Public Speaking\",\n",
        "        \"Financial Analysis\", \"Market Research\", \"Customer Relationship Management\",\n",
        "        \"Team Management\", \"Business Strategy\", \"Consulting\", \"Operations Management\"\n",
        "    ]\n",
        "\n",
        "    creative_skills = [\n",
        "        \"Graphic Design\", \"UI/UX Design\", \"Content Creation\", \"Copywriting\",\n",
        "        \"Video Production\", \"Photography\", \"Adobe Creative Suite\", \"Branding\",\n",
        "        \"Social Media Marketing\", \"Content Strategy\", \"Animation\", \"Illustration\"\n",
        "    ]\n",
        "\n",
        "    general_skills = [\n",
        "        \"Communication\", \"Teamwork\", \"Problem Solving\", \"Critical Thinking\",\n",
        "        \"Time Management\", \"Adaptability\", \"Creativity\", \"Emotional Intelligence\",\n",
        "        \"Attention to Detail\", \"Organization\", \"Research\", \"Presentation Skills\"\n",
        "    ]\n",
        "\n",
        "    # Create a copy of the dataframe\n",
        "    df_with_skills = df.copy()\n",
        "\n",
        "    # Add skills based on position\n",
        "    df_with_skills['skills'] = df_with_skills.apply(\n",
        "        lambda row: assign_skills_by_position(\n",
        "            row['Position'],\n",
        "            tech_skills,\n",
        "            business_skills,\n",
        "            creative_skills,\n",
        "            general_skills\n",
        "        ),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return df_with_skills\n",
        "\n",
        "def assign_skills_by_position(position, tech_skills, business_skills, creative_skills, general_skills):\n",
        "    position = str(position).lower()\n",
        "\n",
        "    # Determine which skill pools to use based on position keywords\n",
        "    if any(keyword in position for keyword in ['engineer', 'developer', 'data', 'tech', 'software', 'it', 'analyst']):\n",
        "        primary_pool = tech_skills\n",
        "        secondary_pool = general_skills\n",
        "        tertiary_pool = business_skills\n",
        "    elif any(keyword in position for keyword in ['manager', 'director', 'executive', 'ceo', 'cfo', 'coo', 'founder', 'president']):\n",
        "        primary_pool = business_skills\n",
        "        secondary_pool = general_skills\n",
        "        tertiary_pool = tech_skills\n",
        "    elif any(keyword in position for keyword in ['design', 'creative', 'artist', 'writer', 'content', 'marketing']):\n",
        "        primary_pool = creative_skills\n",
        "        secondary_pool = general_skills\n",
        "        tertiary_pool = business_skills\n",
        "    else:\n",
        "        primary_pool = general_skills\n",
        "        secondary_pool = random.choice([tech_skills, business_skills, creative_skills])\n",
        "        tertiary_pool = random.choice([tech_skills, business_skills, creative_skills])\n",
        "\n",
        "    # Select 2-3 skills from primary pool\n",
        "    num_primary = random.randint(2, 3)\n",
        "    primary_skills = random.sample(primary_pool, min(num_primary, len(primary_pool)))\n",
        "\n",
        "    # Select 1-2 skills from secondary pool\n",
        "    num_secondary = random.randint(1, 2)\n",
        "    secondary_skills = random.sample(secondary_pool, min(num_secondary, len(secondary_pool)))\n",
        "\n",
        "    # Occasionally add a skill from tertiary pool\n",
        "    tertiary_skills = []\n",
        "    if random.random() < 0.3:  # 30% chance\n",
        "        tertiary_skills = [random.choice(tertiary_pool)]\n",
        "\n",
        "    # Combine skills and return as comma-separated string\n",
        "    all_skills = primary_skills + secondary_skills + tertiary_skills\n",
        "    return \", \".join(all_skills)\n",
        "\n",
        "# Upload multiple LinkedIn connections CSV files\n",
        "from google.colab import files\n",
        "print(\"Upload Soham's LinkedIn connections CSV file:\")\n",
        "uploaded_soham = files.upload()  # This will prompt you to upload Soham's connections.csv file\n",
        "\n",
        "print(\"\\nUpload Emily's LinkedIn connections CSV file:\")\n",
        "uploaded_emily = files.upload()  # This will prompt you to upload Emily's connections.csv file\n",
        "\n",
        "# Process each file\n",
        "soham_df = process_connections_file(list(uploaded_soham.keys())[0], \"Soham\", id_offset=0)\n",
        "emily_df = process_connections_file(list(uploaded_emily.keys())[0], \"Emily\", id_offset=10000)\n",
        "\n",
        "# Combine the dataframes\n",
        "combined_df = pd.concat([soham_df, emily_df], ignore_index=True)\n",
        "\n",
        "# Generate random skills for connections\n",
        "combined_df = generate_random_skills(combined_df)\n",
        "\n",
        "# Display basic statistics\n",
        "print(\"\\nCombined LinkedIn Connections Data:\")\n",
        "print(f\"Total connections from Soham: {len(soham_df)}\")\n",
        "print(f\"Total connections from Emily: {len(emily_df)}\")\n",
        "print(f\"Total combined connections: {len(combined_df)}\")\n",
        "\n",
        "# Display sample of combined data with skills\n",
        "print(\"\\nSample of combined data with generated skills:\")\n",
        "print(combined_df[['full_name', 'Company', 'Position', 'skills']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "ycGzGcbzvJ40",
        "outputId": "9acda003-f762-404a-ffd8-708ab0ad26ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload Soham's LinkedIn connections CSV file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-51151d44-4992-4bfa-9a53-4f0c2375b735\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-51151d44-4992-4bfa-9a53-4f0c2375b735\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sohamconnections.csv to sohamconnections (1).csv\n",
            "\n",
            "Upload Emily's LinkedIn connections CSV file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1ada4254-6922-466c-a88a-72bce3f31ab2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1ada4254-6922-466c-a88a-72bce3f31ab2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving emilyconnections.csv to emilyconnections (1).csv\n",
            "\n",
            "Combined LinkedIn Connections Data:\n",
            "Total connections from Soham: 494\n",
            "Total connections from Emily: 470\n",
            "Total combined connections: 964\n",
            "\n",
            "Sample of combined data with generated skills:\n",
            "           full_name                                     Company  \\\n",
            "0      Akash Sonowal                                NoBroker.com   \n",
            "1       Sahil Lalani                             Stealth Startup   \n",
            "2          Aman Daga                                      PayPal   \n",
            "3  Ella Bullock-Papa  Stanford King Center on Global Development   \n",
            "4     Jamie Burnette                                 Capital One   \n",
            "\n",
            "                                            Position  \\\n",
            "0                                  Data Scientist II   \n",
            "1                                  Software Engineer   \n",
            "2          Tech Product Manager - AI Personalization   \n",
            "3                                 Research Assistant   \n",
            "4  Business Analyst - Portfolio Strategy & Analyt...   \n",
            "\n",
            "                                              skills  \n",
            "0  Cloud Computing, AWS, Data Analysis, Attention...  \n",
            "1                  Docker, Big Data, Problem Solving  \n",
            "2  JavaScript, Cloud Computing, DevOps, Adaptability  \n",
            "3          Critical Thinking, Research, Illustration  \n",
            "4  Azure, Node.js, Big Data, Problem Solving, Bus...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a NetworkX graph with improved structure and FEWER edges\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes (connections) with attributes including skills\n",
        "for idx, row in combined_df.iterrows():\n",
        "    G.add_node(row['id'],\n",
        "               name=row['full_name'],\n",
        "               company=row['Company'],\n",
        "               position=row['Position'],\n",
        "               email=row['Email Address'],\n",
        "               owner=row['owner'],\n",
        "               skills=row['skills'])  # Add skills attribute\n",
        "\n",
        "# Create a more selective edge creation strategy\n",
        "# 1. For each person, connect to at most 5 random people from the same company\n",
        "companies = combined_df['Company'].unique()\n",
        "for company in companies:\n",
        "    if company != 'Unknown':\n",
        "        same_company = combined_df[combined_df['Company'] == company]['id'].tolist()\n",
        "        # Only create edges if there are multiple people at the company\n",
        "        if len(same_company) > 1:\n",
        "            # For each person, connect to at most 5 others from same company\n",
        "            for person in same_company:\n",
        "                # Get other people at same company\n",
        "                others = [p for p in same_company if p != person]\n",
        "                # Connect to at most 5 random people (or fewer if not enough)\n",
        "                connect_to = min(5, len(others))\n",
        "                if connect_to > 0:\n",
        "                    random_others = random.sample(others, connect_to)\n",
        "                    for other in random_others:\n",
        "                        G.add_edge(person, other, relationship='same_company')\n",
        "\n",
        "# 2. Create edges between people with similar skills\n",
        "# Extract all skills\n",
        "all_skills = set()\n",
        "for _, row in combined_df.iterrows():\n",
        "    skills = row['skills'].lower().split(',')\n",
        "    for skill in skills:\n",
        "        all_skills.add(skill.strip())\n",
        "\n",
        "# Create a dictionary mapping skills to people\n",
        "skill_to_people = {skill: [] for skill in all_skills}\n",
        "for idx, row in combined_df.iterrows():\n",
        "    person_skills = [s.strip().lower() for s in row['skills'].split(',')]\n",
        "    for skill in person_skills:\n",
        "        if skill in skill_to_people:\n",
        "            skill_to_people[skill].append(row['id'])\n",
        "\n",
        "# Create edges between people with common skills (max 3 connections per skill)\n",
        "for skill, people in skill_to_people.items():\n",
        "    if len(people) > 1:\n",
        "        for person in people:\n",
        "            others = [p for p in people if p != person]\n",
        "            # Connect to at most 3 random people with the same skill\n",
        "            connect_to = min(3, len(others))\n",
        "            if connect_to > 0:\n",
        "                random_others = random.sample(others, connect_to)\n",
        "                for other in random_others:\n",
        "                    if not G.has_edge(person, other):\n",
        "                        G.add_edge(person, other, relationship='similar_skills')\n",
        "\n",
        "# 3. Create a limited number of edges between connections of the same owner\n",
        "# Instead of connecting everyone to everyone, create a more realistic network\n",
        "for owner in [\"Soham\", \"Emily\"]:\n",
        "    owner_connections = combined_df[combined_df['owner'] == owner]['id'].tolist()\n",
        "    # Create a more realistic network structure - each person connects to ~5 others\n",
        "    for person in owner_connections:\n",
        "        others = [p for p in owner_connections if p != person]\n",
        "        # Connect to at most 5 random people (or fewer if not enough)\n",
        "        connect_to = min(5, len(others))\n",
        "        if connect_to > 0:\n",
        "            random_others = random.sample(others, connect_to)\n",
        "            for other in random_others:\n",
        "                if not G.has_edge(person, other):\n",
        "                    G.add_edge(person, other, relationship='same_owner')\n",
        "\n",
        "# Basic graph statistics\n",
        "print(f\"Number of nodes (connections): {G.number_of_nodes()}\")\n",
        "print(f\"Number of edges (relationships): {G.number_of_edges()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK6lGV1svTGi",
        "outputId": "0b33f6cf-554a-4fa3-f7a3-595f09406659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes (connections): 964\n",
            "Number of edges (relationships): 17881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to ArangoDB using the provided credentials\n",
        "client = ArangoClient(hosts=\"https://df7687e8971e.arangodb.cloud:8529\")\n",
        "db = client.db(username=\"root\", password=\"1ADDF5Q0eJypkH0QdJNs\", verify=True)\n",
        "\n",
        "# Create collections if they don't exist\n",
        "if not db.has_collection('LinkedIn_node'):\n",
        "    db.create_collection('LinkedIn_node')\n",
        "if not db.has_collection('LinkedIn_node_to_LinkedIn_node'):\n",
        "    db.create_collection('LinkedIn_node_to_LinkedIn_node', edge=True)\n",
        "\n",
        "# Create the graph in ArangoDB\n",
        "if not db.has_graph('LinkedIn'):\n",
        "    graph = db.create_graph('LinkedIn', edge_definitions=[\n",
        "        {\n",
        "            'edge_collection': 'LinkedIn_node_to_LinkedIn_node',\n",
        "            'from_vertex_collections': ['LinkedIn_node'],\n",
        "            'to_vertex_collections': ['LinkedIn_node']\n",
        "        }\n",
        "    ])\n",
        "else:\n",
        "    graph = db.graph('LinkedIn')"
      ],
      "metadata": {
        "id": "pfLD_TCqvVMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear existing data to avoid conflicts\n",
        "try:\n",
        "    db.collection('LinkedIn_node_to_LinkedIn_node').truncate()\n",
        "    db.collection('LinkedIn_node').truncate()\n",
        "    print(\"Cleared existing data in ArangoDB\")\n",
        "except Exception as e:\n",
        "    print(f\"Error clearing data: {e}\")\n",
        "\n",
        "# Add nodes to ArangoDB with error handling\n",
        "node_count = 0\n",
        "for node_id in G.nodes():\n",
        "    node_data = G.nodes[node_id]\n",
        "    # Create a document key from the node ID\n",
        "    key = str(node_id)\n",
        "\n",
        "    try:\n",
        "        # Add the node to ArangoDB\n",
        "        db.collection('LinkedIn_node').insert({\n",
        "            '_key': key,\n",
        "            'name': node_data.get('name', ''),\n",
        "            'company': node_data.get('company', ''),\n",
        "            'position': node_data.get('position', ''),\n",
        "            'email': node_data.get('email', ''),\n",
        "            'owner': node_data.get('owner', ''),\n",
        "            'skills': node_data.get('skills', '')\n",
        "        })\n",
        "        node_count += 1\n",
        "\n",
        "        # Print progress every 100 nodes\n",
        "        if node_count % 100 == 0:\n",
        "            print(f\"Added {node_count} nodes so far...\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error inserting node {key}: {e}\")\n",
        "\n",
        "# Add edges to ArangoDB with error handling\n",
        "edge_count = 0\n",
        "for u, v, data in G.edges(data=True):\n",
        "    # Create edge document\n",
        "    edge = {\n",
        "        '_from': f'LinkedIn_node/{u}',\n",
        "        '_to': f'LinkedIn_node/{v}',\n",
        "        'relationship': data.get('relationship', 'connection')\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Add the edge to ArangoDB\n",
        "        db.collection('LinkedIn_node_to_LinkedIn_node').insert(edge)\n",
        "        edge_count += 1\n",
        "\n",
        "        # Print progress every 100 edges\n",
        "        if edge_count % 100 == 0:\n",
        "            print(f\"Added {edge_count} edges so far...\")\n",
        "    except Exception as e:\n",
        "        # Skip duplicate edges\n",
        "        pass\n",
        "\n",
        "print(f\"Graph successfully persisted to ArangoDB with {node_count} nodes and {edge_count} edges!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6XcaboN8vVG7",
        "outputId": "7b3c3da5-4acb-46e0-9a30-dbd1015e9566",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleared existing data in ArangoDB\n",
            "Added 100 nodes so far...\n",
            "Added 200 nodes so far...\n",
            "Added 300 nodes so far...\n",
            "Added 400 nodes so far...\n",
            "Error inserting node 426: [HTTP 400][ERR 600] VPackError error: Expecting digit\n",
            "Added 500 nodes so far...\n",
            "Added 600 nodes so far...\n",
            "Error inserting node 10137: [HTTP 400][ERR 600] VPackError error: Expecting digit\n",
            "Added 700 nodes so far...\n",
            "Added 800 nodes so far...\n",
            "Added 900 nodes so far...\n",
            "Added 100 edges so far...\n",
            "Added 200 edges so far...\n",
            "Added 300 edges so far...\n",
            "Added 400 edges so far...\n",
            "Added 500 edges so far...\n",
            "Added 600 edges so far...\n",
            "Added 700 edges so far...\n",
            "Added 800 edges so far...\n",
            "Added 900 edges so far...\n",
            "Added 1000 edges so far...\n",
            "Added 1100 edges so far...\n",
            "Added 1200 edges so far...\n",
            "Added 1300 edges so far...\n",
            "Added 1400 edges so far...\n",
            "Added 1500 edges so far...\n",
            "Added 1600 edges so far...\n",
            "Added 1700 edges so far...\n",
            "Added 1800 edges so far...\n",
            "Added 1900 edges so far...\n",
            "Added 2000 edges so far...\n",
            "Added 2100 edges so far...\n",
            "Added 2200 edges so far...\n",
            "Added 2300 edges so far...\n",
            "Added 2400 edges so far...\n",
            "Added 2500 edges so far...\n",
            "Added 2600 edges so far...\n",
            "Added 2700 edges so far...\n",
            "Added 2800 edges so far...\n",
            "Added 2900 edges so far...\n",
            "Added 3000 edges so far...\n",
            "Added 3100 edges so far...\n",
            "Added 3200 edges so far...\n",
            "Added 3300 edges so far...\n",
            "Added 3400 edges so far...\n",
            "Added 3500 edges so far...\n",
            "Added 3600 edges so far...\n",
            "Added 3700 edges so far...\n",
            "Added 3800 edges so far...\n",
            "Added 3900 edges so far...\n",
            "Added 4000 edges so far...\n",
            "Added 4100 edges so far...\n",
            "Added 4200 edges so far...\n",
            "Added 4300 edges so far...\n",
            "Added 4400 edges so far...\n",
            "Added 4500 edges so far...\n",
            "Added 4600 edges so far...\n",
            "Added 4700 edges so far...\n",
            "Added 4800 edges so far...\n",
            "Added 4900 edges so far...\n",
            "Added 5000 edges so far...\n",
            "Added 5100 edges so far...\n",
            "Added 5200 edges so far...\n",
            "Added 5300 edges so far...\n",
            "Added 5400 edges so far...\n",
            "Added 5500 edges so far...\n",
            "Added 5600 edges so far...\n",
            "Added 5700 edges so far...\n",
            "Added 5800 edges so far...\n",
            "Added 5900 edges so far...\n",
            "Added 6000 edges so far...\n",
            "Added 6100 edges so far...\n",
            "Added 6200 edges so far...\n",
            "Added 6300 edges so far...\n",
            "Added 6400 edges so far...\n",
            "Added 6500 edges so far...\n",
            "Added 6600 edges so far...\n",
            "Added 6700 edges so far...\n",
            "Added 6800 edges so far...\n",
            "Added 6900 edges so far...\n",
            "Added 7000 edges so far...\n",
            "Added 7100 edges so far...\n",
            "Added 7200 edges so far...\n",
            "Added 7300 edges so far...\n",
            "Added 7400 edges so far...\n",
            "Added 7500 edges so far...\n",
            "Added 7600 edges so far...\n",
            "Added 7700 edges so far...\n",
            "Added 7800 edges so far...\n",
            "Added 7900 edges so far...\n",
            "Added 8000 edges so far...\n",
            "Added 8100 edges so far...\n",
            "Added 8200 edges so far...\n",
            "Added 8300 edges so far...\n",
            "Added 8400 edges so far...\n",
            "Added 8500 edges so far...\n",
            "Added 8600 edges so far...\n",
            "Added 8700 edges so far...\n",
            "Added 8800 edges so far...\n",
            "Added 8900 edges so far...\n",
            "Added 9000 edges so far...\n",
            "Added 9100 edges so far...\n",
            "Added 9200 edges so far...\n",
            "Added 9300 edges so far...\n",
            "Added 9400 edges so far...\n",
            "Added 9500 edges so far...\n",
            "Added 9600 edges so far...\n",
            "Added 9700 edges so far...\n",
            "Added 9800 edges so far...\n",
            "Added 9900 edges so far...\n",
            "Added 10000 edges so far...\n",
            "Added 10100 edges so far...\n",
            "Added 10200 edges so far...\n",
            "Added 10300 edges so far...\n",
            "Added 10400 edges so far...\n",
            "Added 10500 edges so far...\n",
            "Added 10600 edges so far...\n",
            "Added 10700 edges so far...\n",
            "Added 10800 edges so far...\n",
            "Added 10900 edges so far...\n",
            "Added 11000 edges so far...\n",
            "Added 11100 edges so far...\n",
            "Added 11200 edges so far...\n",
            "Added 11300 edges so far...\n",
            "Added 11400 edges so far...\n",
            "Added 11500 edges so far...\n",
            "Added 11600 edges so far...\n",
            "Added 11700 edges so far...\n",
            "Added 11800 edges so far...\n",
            "Added 11900 edges so far...\n",
            "Added 12000 edges so far...\n",
            "Added 12100 edges so far...\n",
            "Added 12200 edges so far...\n",
            "Added 12300 edges so far...\n",
            "Added 12400 edges so far...\n",
            "Added 12500 edges so far...\n",
            "Added 12600 edges so far...\n",
            "Added 12700 edges so far...\n",
            "Added 12800 edges so far...\n",
            "Added 12900 edges so far...\n",
            "Added 13000 edges so far...\n",
            "Added 13100 edges so far...\n",
            "Added 13200 edges so far...\n",
            "Added 13300 edges so far...\n",
            "Added 13400 edges so far...\n",
            "Added 13500 edges so far...\n",
            "Added 13600 edges so far...\n",
            "Added 13700 edges so far...\n",
            "Added 13800 edges so far...\n",
            "Added 13900 edges so far...\n",
            "Added 14000 edges so far...\n",
            "Added 14100 edges so far...\n",
            "Added 14200 edges so far...\n",
            "Added 14300 edges so far...\n",
            "Added 14400 edges so far...\n",
            "Added 14500 edges so far...\n",
            "Added 14600 edges so far...\n",
            "Added 14700 edges so far...\n",
            "Added 14800 edges so far...\n",
            "Added 14900 edges so far...\n",
            "Added 15000 edges so far...\n",
            "Added 15100 edges so far...\n",
            "Added 15200 edges so far...\n",
            "Added 15300 edges so far...\n",
            "Added 15400 edges so far...\n",
            "Added 15500 edges so far...\n",
            "Added 15600 edges so far...\n",
            "Added 15700 edges so far...\n",
            "Added 15800 edges so far...\n",
            "Added 15900 edges so far...\n",
            "Added 16000 edges so far...\n",
            "Added 16100 edges so far...\n",
            "Added 16200 edges so far...\n",
            "Added 16300 edges so far...\n",
            "Added 16400 edges so far...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c0ab12a9a38d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Add the edge to ArangoDB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LinkedIn_node_to_LinkedIn_node'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0medge_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/collection.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, document, return_new, sync, silent, overwrite, return_old, overwrite_mode, keep_none, merge, refill_index_caches, version_attribute)\u001b[0m\n\u001b[1;32m   2699\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m     def update(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/api.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, request, response_handler)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAPI\u001b[0m \u001b[0mexecution\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, request, response_handler)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAPI\u001b[0m \u001b[0mexecution\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/connection.py\u001b[0m in \u001b[0;36msend_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[1;32m    310\u001b[0m         \u001b[0mhost_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_host_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/connection.py\u001b[0m in \u001b[0;36mprocess_request\u001b[0;34m(self, host_index, request, auth)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mtries\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_tries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 resp = self._http.send_request(\n\u001b[0m\u001b[1;32m    157\u001b[0m                     \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sessions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhost_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/arango/http.py\u001b[0m in \u001b[0;36msend_request\u001b[0;34m(self, session, method, url, headers, params, data, auth)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marango\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[0;32m--> 230\u001b[0;31m         response = session.request(\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1312\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the graph from ArangoDB for querying\n",
        "G_adb = nx.Graph()\n",
        "\n",
        "# Get all nodes from ArangoDB\n",
        "cursor = db.aql.execute(\n",
        "    \"FOR doc IN LinkedIn_node RETURN doc\"\n",
        ")\n",
        "for node in cursor:\n",
        "    G_adb.add_node(\n",
        "        node['_key'],\n",
        "        name=node.get('name', ''),\n",
        "        company=node.get('company', ''),\n",
        "        position=node.get('position', ''),\n",
        "        email=node.get('email', ''),\n",
        "        owner=node.get('owner', ''),\n",
        "        skills=node.get('skills', '')\n",
        "    )\n",
        "\n",
        "# Get all edges from ArangoDB\n",
        "cursor = db.aql.execute(\n",
        "    \"FOR edge IN LinkedIn_node_to_LinkedIn_node RETURN edge\"\n",
        ")\n",
        "for edge in cursor:\n",
        "    from_key = edge['_from'].split('/')[1]\n",
        "    to_key = edge['_to'].split('/')[1]\n",
        "    G_adb.add_edge(from_key, to_key, relationship=edge.get('relationship', 'connection'))\n",
        "\n",
        "print(f\"Loaded graph from ArangoDB with {G_adb.number_of_nodes()} nodes and {G_adb.number_of_edges()} edges\")"
      ],
      "metadata": {
        "id": "sILShaKuvVAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ArangoGraph object for LangChain\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "arango_graph = ArangoGraph(db)\n",
        "\n",
        "# Initialize the LLM\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "ORwC5lXVvU4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tools for the agent\n",
        "from langchain_core.tools import tool\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "import re\n",
        "import networkx as nx\n",
        "\n",
        "@tool\n",
        "def favourite_fruit(query: str):\n",
        "    \"\"\"You are responsible for responding to being asked what your favourite fruit is.\n",
        "    You must say Avocado!\n",
        "    \"\"\"\n",
        "    return \"Avocado!\"\n",
        "\n",
        "@tool\n",
        "def text_to_aql_to_text(query: str):\n",
        "    \"\"\"This tool is available to invoke the\n",
        "    ArangoGraphQAChain object, which enables you to\n",
        "    translate a Natural Language Query into AQL, execute\n",
        "    the query, and translate the result back into Natural Language.\n",
        "    \"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    chain = ArangoGraphQAChain.from_llm(\n",
        "        llm=llm,\n",
        "        graph=arango_graph,\n",
        "        verbose=True,\n",
        "        allow_dangerous_requests=True\n",
        "    )\n",
        "\n",
        "    result = chain.invoke(query)\n",
        "\n",
        "    return str(result[\"result\"])\n",
        "\n",
        "@tool\n",
        "def text_to_nx_algorithm_to_text(query):\n",
        "    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
        "    the ArangoDB Graph. You are responsible for accepting the\n",
        "    Natural Language Query, establishing which algorithm needs to\n",
        "    be executed, executing the algorithm, and translating the results back\n",
        "    to Natural Language, with respect to the original query.\n",
        "\n",
        "    If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n",
        "    this tool.\n",
        "    \"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    print(\"1) Generating NetworkX code\")\n",
        "\n",
        "    text_to_nx = llm.invoke(f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "    Use PageRank algorithm when appropriate for influence or importance analysis.\n",
        "\n",
        "    Only assume that networkx is installed, and other base python dependencies.\n",
        "\n",
        "    Always store the PageRank scores in a variable called `pagerank_scores` before using them.\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Make sure that `FINAL_RESULT` stores a short & concise answer. Avoid setting this variable to a long sequence.\n",
        "\n",
        "    Your code:\n",
        "    \"\"\").content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print(\"2) Executing NetworkX code\")\n",
        "\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    try:\n",
        "        exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        result = local_vars.get(\"FINAL_RESULT\", \"No result produced\")\n",
        "    except Exception as e:\n",
        "        print(f\"EXEC ERROR: {e}\")\n",
        "        return f\"Error in NetworkX analysis: {e}\"\n",
        "\n",
        "    print(\"3) Generating natural language response\")\n",
        "\n",
        "    text_to_nl = llm.invoke(f\"\"\"\n",
        "    I was asked: \"{query}\"\n",
        "\n",
        "    I executed a NetworkX algorithm and got the following result: {result}\n",
        "\n",
        "    Please translate this result into a natural language response that directly answers the original query.\n",
        "    Be concise but informative. Explain any technical terms if necessary.\n",
        "    \"\"\").content\n",
        "\n",
        "    return text_to_nl\n",
        "\n",
        "@tool\n",
        "def hybrid_query_execution(query):\n",
        "    \"\"\"This tool is available to execute hybrid queries that combine AQL and NetworkX algorithms.\n",
        "    It's designed for complex queries that require both data retrieval and graph analytics.\n",
        "    \"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    # Step 1: Plan the hybrid query approach\n",
        "    print(\"Hybrid Query Planning\")\n",
        "\n",
        "    aql_planning = llm.invoke(f\"\"\"\n",
        "    I need to answer this query about a LinkedIn network: \"{query}\"\n",
        "\n",
        "    This requires a hybrid approach using both AQL for data retrieval and NetworkX for graph analytics.\n",
        "\n",
        "    First, I need to determine what data to retrieve with AQL. Write a description of what\n",
        "    data we should retrieve with AQL (don't write the actual AQL yet).\n",
        "\n",
        "    Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    print(\"Hybrid Query Planning - AQL Component:\")\n",
        "    print(aql_planning)\n",
        "\n",
        "    # Step 2: Generate and execute the AQL query\n",
        "    aql_chain = ArangoGraphQAChain.from_llm(\n",
        "        llm=llm,\n",
        "        graph=arango_graph,\n",
        "        verbose=False,\n",
        "        allow_dangerous_requests=True\n",
        "    )\n",
        "\n",
        "    aql_result = aql_chain.invoke(f\"Retrieve the following data: {aql_planning}\")\n",
        "\n",
        "    print(\"\\nAQL Result:\")\n",
        "    print(aql_result[\"result\"])\n",
        "\n",
        "    # Step 3: Generate NetworkX code to analyze the retrieved data\n",
        "    nx_code = llm.invoke(f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have retrieved the following data using AQL: {aql_result[\"result\"]}\n",
        "\n",
        "    Now I need to perform advanced analysis on this data to answer the original query: \"{query}\"\n",
        "\n",
        "    Generate Python code using NetworkX algorithms to analyze this data and answer the query.\n",
        "    Use PageRank algorithm when appropriate for influence or importance analysis.\n",
        "\n",
        "    Always store the PageRank scores in a variable called `pagerank_scores` before using them.\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Your code:\n",
        "    \"\"\").content\n",
        "\n",
        "    nx_code_cleaned = re.sub(r\"^```python\\n|```$\", \"\", nx_code, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print(\"\\nNetworkX Analysis Code:\")\n",
        "    print(nx_code_cleaned)\n",
        "\n",
        "    # Step 4: Execute the NetworkX code\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx, \"aql_data\": aql_result[\"result\"]}\n",
        "    local_vars = {}\n",
        "\n",
        "    try:\n",
        "        exec(nx_code_cleaned, global_vars, local_vars)\n",
        "        nx_result = local_vars.get(\"FINAL_RESULT\", \"No result produced\")\n",
        "    except Exception as e:\n",
        "        print(f\"EXEC ERROR: {e}\")\n",
        "        return f\"Error in NetworkX analysis: {e}\"\n",
        "\n",
        "    # Step 5: Generate the final response\n",
        "    final_response = llm.invoke(f\"\"\"\n",
        "    I was asked: \"{query}\"\n",
        "\n",
        "    First, I retrieved data using AQL: {aql_result[\"result\"]}\n",
        "\n",
        "    Then, I analyzed this data using NetworkX algorithms and got: {nx_result}\n",
        "\n",
        "    Based on both the data retrieval and analysis, provide a comprehensive answer to the original query.\n",
        "    Make sure to explain insights from both the graph structure and the analytics performed.\n",
        "\n",
        "    Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "nMPPjSvEvUwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatic Query Router\n",
        "def determine_query_type(query):\n",
        "    \"\"\"\n",
        "    Uses LLM to determine the best query type for a given question\n",
        "    \"\"\"\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    response = llm.invoke(f\"\"\"\n",
        "    I need to determine the best query type for this question about a LinkedIn network: \"{query}\"\n",
        "\n",
        "    Please classify this query into one of these categories:\n",
        "\n",
        "    1. SIMPLE QUERY: Basic retrieval questions that can be answered with AQL, like \"Who works at Google?\" or \"Find all software engineers\"\n",
        "\n",
        "    2. COMPLEX QUERY: Questions requiring graph algorithms like PageRank, centrality measures, community detection, like \"Who is the most influential person?\" or \"What communities exist in the network?\"\n",
        "\n",
        "    3. HYBRID QUERY: Questions requiring both data retrieval and complex analysis, like \"Who are the most influential people at Microsoft?\" or \"Which second-degree connections should I prioritize meeting?\"\n",
        "\n",
        "    Respond with ONLY ONE of these exact phrases: \"SIMPLE QUERY\", \"COMPLEX QUERY\", or \"HYBRID QUERY\".\n",
        "    \"\"\").content\n",
        "\n",
        "    # Clean up response to get just the classification\n",
        "    response = response.strip().upper()\n",
        "\n",
        "    if \"SIMPLE QUERY\" in response:\n",
        "        return \"Simple Query\", text_to_aql_to_text\n",
        "    elif \"COMPLEX QUERY\" in response:\n",
        "        return \"Complex Query\", text_to_nx_algorithm_to_text\n",
        "    elif \"HYBRID QUERY\" in response:\n",
        "        return \"Hybrid Query\", hybrid_query_execution\n",
        "    else:\n",
        "        return \"Simple Query\", text_to_aql_to_text  # Default to simple query"
      ],
      "metadata": {
        "id": "7YGKEk2hvUi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the agent with a few queries\n",
        "print(\"Query 1: Who in my network works at Google?\")\n",
        "result1, type1 = query_graph(\"Who in my network works at Google?\")\n",
        "print(f\"Query Type: {type1}\")\n",
        "print(result1)\n",
        "\n",
        "print(\"\\nQuery 2: Who has the most connections in my network?\")\n",
        "result2, type2 = query_graph(\"Who has the most connections in my network?\")\n",
        "print(f\"Query Type: {type2}\")\n",
        "print(result2)\n",
        "\n",
        "print(\"\\nQuery 3: Find people in my network who have skills in data science\")\n",
        "result3, type3 = query_graph(\"Find people in my network who have skills in data science\")\n",
        "print(f\"Query Type: {type3}\")\n",
        "print(result3)\n",
        "\n",
        "print(\"\\nQuery 4: Who are the most influential people at Microsoft in my network?\")\n",
        "result4, type4 = query_graph(\"Who are the most influential people at Microsoft in my network?\")\n",
        "print(f\"Query Type: {type4}\")\n",
        "print(result4)"
      ],
      "metadata": {
        "id": "8TtkE1VFwKPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "# Function to get list of companies for dropdown\n",
        "def get_company_list():\n",
        "    companies = set()\n",
        "    for _, attr in G_adb.nodes(data=True):\n",
        "        company = attr.get('company', '')\n",
        "        if company and company != 'Unknown':\n",
        "            companies.add(company)\n",
        "\n",
        "    return [\"All Companies\"] + sorted(list(companies))\n",
        "\n",
        "# Function to get list of skills for dropdown\n",
        "def get_skills_list():\n",
        "    all_skills = set()\n",
        "    for _, attr in G_adb.nodes(data=True):\n",
        "        skills = attr.get('skills', '').split(',')\n",
        "        for skill in skills:\n",
        "            skill = skill.strip()\n",
        "            if skill:\n",
        "                all_skills.add(skill)\n",
        "\n",
        "    return [\"All Skills\"] + sorted(list(all_skills))\n",
        "\n",
        "# Function to create a network visualization\n",
        "def create_network_visualization(owner_filter=None, company_filter=None, skill_filter=None, limit=100):\n",
        "    # Filter graph based on parameters\n",
        "    filtered_nodes = set()\n",
        "\n",
        "    # Apply owner filter\n",
        "    if owner_filter and owner_filter != \"All\":\n",
        "        filtered_nodes = {n for n, attr in G_adb.nodes(data=True) if attr.get('owner') == owner_filter}\n",
        "    else:\n",
        "        filtered_nodes = set(G_adb.nodes())\n",
        "\n",
        "    # Apply company filter\n",
        "    if company_filter and company_filter != \"All Companies\":\n",
        "        company_nodes = {n for n, attr in G_adb.nodes(data=True) if attr.get('company') == company_filter}\n",
        "        filtered_nodes = filtered_nodes.intersection(company_nodes)\n",
        "\n",
        "    # Apply skill filter\n",
        "    if skill_filter and skill_filter != \"All Skills\":\n",
        "                skill_nodes = {n for n, attr in G_adb.nodes(data=True)\n",
        "                      if skill_filter.lower() in attr.get('skills', '').lower()}\n",
        "                        skill_nodes = {n for n, attr in G_adb.nodes(data=True)\n",
        "                      if skill_filter.lower() in attr.get('skills', '').lower()}\n",
        "        filtered_nodes = filtered_nodes.intersection(skill_nodes)\n",
        "\n",
        "    # Create subgraph\n",
        "    filtered_graph = G_adb.subgraph(filtered_nodes)\n",
        "\n",
        "    # If graph is too large, take a sample\n",
        "    if filtered_graph.number_of_nodes() > limit:\n",
        "        # Get top nodes by degree centrality\n",
        "        centrality = nx.degree_centrality(filtered_graph)\n",
        "        top_nodes = sorted(centrality, key=centrality.get, reverse=True)[:limit]\n",
        "        filtered_graph = filtered_graph.subgraph(top_nodes)\n",
        "\n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Use a more efficient layout algorithm\n",
        "    pos = nx.spring_layout(filtered_graph, k=0.3, iterations=50, seed=42)\n",
        "\n",
        "    # Color nodes by owner and relationship type\n",
        "    node_colors = []\n",
        "    for node in filtered_graph.nodes():\n",
        "        owner = filtered_graph.nodes[node].get('owner', '')\n",
        "        if owner == \"Soham\":\n",
        "            node_colors.append(\"#4285F4\")  # Blue for Soham\n",
        "        elif owner == \"Emily\":\n",
        "            node_colors.append(\"#EA4335\")  # Red for Emily\n",
        "        else:\n",
        "            node_colors.append(\"#FBBC05\")  # Yellow for unknown\n",
        "\n",
        "    # Draw nodes with simpler styling\n",
        "    nx.draw_networkx_nodes(filtered_graph, pos, node_size=100, node_color=node_colors, alpha=0.8)\n",
        "\n",
        "    # Draw edges with colors based on relationship type\n",
        "    same_company_edges = [(u, v) for u, v, d in filtered_graph.edges(data=True)\n",
        "                          if d.get('relationship') == 'same_company']\n",
        "    similar_skills_edges = [(u, v) for u, v, d in filtered_graph.edges(data=True)\n",
        "                           if d.get('relationship') == 'similar_skills']\n",
        "    same_owner_edges = [(u, v) for u, v, d in filtered_graph.edges(data=True)\n",
        "                        if d.get('relationship') == 'same_owner']\n",
        "\n",
        "    nx.draw_networkx_edges(filtered_graph, pos, edgelist=same_company_edges,\n",
        "                          alpha=0.5, width=0.5, edge_color='green')\n",
        "    nx.draw_networkx_edges(filtered_graph, pos, edgelist=similar_skills_edges,\n",
        "                          alpha=0.5, width=0.5, edge_color='purple')\n",
        "    nx.draw_networkx_edges(filtered_graph, pos, edgelist=same_owner_edges,\n",
        "                          alpha=0.5, width=0.5, edge_color='orange')\n",
        "\n",
        "    # Draw labels for only a subset of nodes to avoid clutter\n",
        "    if filtered_graph.number_of_nodes() <= 30:\n",
        "        # If few nodes, label all of them\n",
        "        labels = {node: filtered_graph.nodes[node].get('name', '') for node in filtered_graph.nodes()}\n",
        "        nx.draw_networkx_labels(filtered_graph, pos, labels=labels, font_size=8)\n",
        "    else:\n",
        "        # If many nodes, label only the top 15 by degree centrality\n",
        "        centrality = nx.degree_centrality(filtered_graph)\n",
        "        top_nodes = sorted(centrality, key=centrality.get, reverse=True)[:15]\n",
        "        labels = {node: filtered_graph.nodes[node].get('name', '') for node in top_nodes}\n",
        "        nx.draw_networkx_labels(filtered_graph, pos, labels=labels, font_size=8)\n",
        "\n",
        "    # Add a legend\n",
        "    plt.figtext(0.01, 0.01, \"Blue: Soham's connections, Red: Emily's connections\", fontsize=8)\n",
        "    plt.figtext(0.01, 0.03, \"Green: Same company, Purple: Similar skills, Orange: Same owner\", fontsize=8)\n",
        "\n",
        "    # Set title based on filters\n",
        "    title = \"LinkedIn Network\"\n",
        "    if owner_filter and owner_filter != \"All\":\n",
        "        title += f\" - {owner_filter}'s Connections\"\n",
        "    if company_filter and company_filter != \"All Companies\":\n",
        "        title += f\" at {company_filter}\"\n",
        "    if skill_filter and skill_filter != \"All Skills\":\n",
        "        title += f\" with {skill_filter} skills\"\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Save figure to a buffer\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=300, bbox_inches='tight')\n",
        "    buf.seek(0)\n",
        "    plt.close()\n",
        "\n",
        "    # Convert buffer to PIL image\n",
        "    img = Image.open(buf)\n",
        "\n",
        "    # Add network statistics as text\n",
        "    stats_text = f\"\"\"\n",
        "    Network Statistics:\n",
        "    - Nodes: {filtered_graph.number_of_nodes()}\n",
        "    - Edges: {filtered_graph.number_of_edges()}\n",
        "    - Density: {nx.density(filtered_graph):.4f}\n",
        "    - Avg. Clustering: {nx.average_clustering(filtered_graph):.4f}\n",
        "    \"\"\"\n",
        "\n",
        "    return img, stats_text\n",
        "\n",
        "# Function to get network statistics\n",
        "def get_network_stats(owner_filter=None):\n",
        "    # Filter graph by owner if specified\n",
        "    if owner_filter and owner_filter != \"All\":\n",
        "        owner_nodes = [n for n, attr in G_adb.nodes(data=True) if attr.get('owner') == owner_filter]\n",
        "        filtered_graph = G_adb.subgraph(owner_nodes)\n",
        "    else:\n",
        "        filtered_graph = G_adb\n",
        "\n",
        "    # Calculate PageRank\n",
        "    pagerank_scores = nx.pagerank(filtered_graph)\n",
        "\n",
        "    # Get top influential people\n",
        "    top_influential = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "    top_influential_names = [(filtered_graph.nodes[node].get('name', ''), score)\n",
        "                            for node, score in top_influential]\n",
        "\n",
        "    # Basic statistics\n",
        "    stats = {\n",
        "        \"Total Connections\": filtered_graph.number_of_nodes(),\n",
        "        \"Total Relationships\": filtered_graph.number_of_edges(),\n",
        "        \"Network Density\": nx.density(filtered_graph),\n",
        "        \"Average Clustering\": nx.average_clustering(filtered_graph),\n",
        "    }\n",
        "\n",
        "    # Get top companies\n",
        "    companies = {}\n",
        "    for node in filtered_graph.nodes():\n",
        "        company = filtered_graph.nodes[node].get('company', 'Unknown')\n",
        "        if company in companies:\n",
        "            companies[company] += 1\n",
        "        else:\n",
        "            companies[company] = 1\n",
        "\n",
        "    top_companies = sorted(companies.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "    # Get top skills\n",
        "    skills_count = {}\n",
        "    for node in filtered_graph.nodes():\n",
        "        skills = filtered_graph.nodes[node].get('skills', '').split(',')\n",
        "        for skill in skills:\n",
        "            skill = skill.strip()\n",
        "            if skill:\n",
        "                if skill in skills_count:\n",
        "                    skills_count[skill] += 1\n",
        "                else:\n",
        "                    skills_count[skill] = 1\n",
        "\n",
        "    top_skills = sorted(skills_count.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    # Format the output as markdown\n",
        "    output = f\"\"\"\n",
        "    ## Network Statistics for {owner_filter if owner_filter != 'All' else 'All Connections'}\n",
        "\n",
        "    ### Basic Metrics\n",
        "    - **Total Connections**: {stats['Total Connections']}\n",
        "    - **Total Relationships**: {stats['Total Relationships']}\n",
        "    - **Network Density**: {stats['Network Density']:.4f}\n",
        "    - **Average Clustering**: {stats['Average Clustering']:.4f}\n",
        "\n",
        "    ### Top Influential People (PageRank)\n",
        "    \"\"\"\n",
        "\n",
        "    for name, score in top_influential_names:\n",
        "        output += f\"- **{name}**: {score:.4f}\\n\"\n",
        "\n",
        "    output += \"\\n### Top Companies\\n\"\n",
        "    for company, count in top_companies:\n",
        "        output += f\"- **{company}**: {count} connections\\n\"\n",
        "\n",
        "    output += \"\\n### Top Skills\\n\"\n",
        "    for skill, count in top_skills:\n",
        "        output += f\"- **{skill}**: {count} connections\\n\"\n",
        "\n",
        "    return output\n",
        "\n",
        "# Create the Gradio interface for NetworkX AI\n",
        "with gr.Blocks(title=\"NetworkX AI - LinkedIn Network Analyzer\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # NetworkX AI - LinkedIn Network Analyzer\n",
        "\n",
        "    Analyze your professional network with AI-powered graph analytics. This tool helps you discover insights,\n",
        "    find connections, and leverage your network more effectively.\n",
        "\n",
        "    ## Features\n",
        "    - Query your network using natural language\n",
        "    - Visualize connections and relationships\n",
        "    - Analyze network statistics and metrics\n",
        "    - Discover skills and expertise across your network\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tab(\"Query Network\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=3):\n",
        "                query_input = gr.Textbox(\n",
        "                    label=\"Ask a question about your network\",\n",
        "                    placeholder=\"e.g., Who are the most influential people in my network?\",\n",
        "                    lines=2\n",
        "                )\n",
        "                query_type = gr.Radio(\n",
        "                    [\"Auto Detect\", \"Simple Query\", \"Complex Query\", \"Hybrid Query\"],\n",
        "                    label=\"Query Type\",\n",
        "                    value=\"Auto Detect\"\n",
        "                )\n",
        "                query_button = gr.Button(\"Submit Query\")\n",
        "\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"\"\"\n",
        "                ### Query Types\n",
        "                - **Simple Query**: Basic retrieval (Who works at Google?)\n",
        "                - **Complex Query**: Graph algorithms (Who is most influential?)\n",
        "                - **Hybrid Query**: Combined analysis (Who should I meet next?)\n",
        "                \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            query_result = gr.Textbox(label=\"Answer\", lines=10)\n",
        "            query_type_result = gr.Textbox(label=\"Query Type Used\")\n",
        "\n",
        "        query_button.click(\n",
        "            lambda q, t: query_graph(q, None if t == \"Auto Detect\" else t),\n",
        "            inputs=[query_input, query_type],\n",
        "            outputs=[query_result, query_type_result]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Network Visualization\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                viz_owner_filter = gr.Radio(\n",
        "                    [\"All\", \"Soham\", \"Emily\"],\n",
        "                    label=\"Filter by network owner\",\n",
        "                    value=\"All\"\n",
        "                )\n",
        "                viz_company_filter = gr.Dropdown(\n",
        "                    choices=get_company_list(),\n",
        "                    label=\"Filter by company\",\n",
        "                    value=\"All Companies\"\n",
        "                )\n",
        "                viz_skill_filter = gr.Dropdown(\n",
        "                    choices=get_skills_list(),\n",
        "                    label=\"Filter by skill\",\n",
        "                    value=\"All Skills\"\n",
        "                )\n",
        "                viz_button = gr.Button(\"Generate Visualization\")\n",
        "\n",
        "            with gr.Column(scale=3):\n",
        "                viz_output = gr.Image(label=\"Network Visualization\")\n",
        "                viz_stats = gr.Textbox(label=\"Visualization Statistics\", lines=5)\n",
        "\n",
        "        viz_button.click(\n",
        "            create_network_visualization,\n",
        "            inputs=[viz_owner_filter, viz_company_filter, viz_skill_filter],\n",
        "            outputs=[viz_output, viz_stats]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Network Statistics\"):\n",
        "        with gr.Row():\n",
        "            stats_owner_filter = gr.Radio(\n",
        "                [\"All\", \"Soham\", \"Emily\"],\n",
        "                label=\"Filter by network owner\",\n",
        "                value=\"All\"\n",
        "            )\n",
        "            stats_button = gr.Button(\"Generate Network Statistics\")\n",
        "\n",
        "        stats_output = gr.Markdown()\n",
        "\n",
        "        stats_button.click(\n",
        "            get_network_stats,\n",
        "            inputs=stats_owner_filter,\n",
        "            outputs=stats_output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Sample Queries\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ## Sample Queries to Try\n",
        "\n",
        "        ### Simple Queries\n",
        "        - Who in my network works at Google?\n",
        "        - Find all connections who are software engineers\n",
        "        - Which companies have the most people in my network?\n",
        "        - Who in my network has skills in Python?\n",
        "\n",
        "        ### Complex Queries (Using PageRank and other algorithms)\n",
        "        - Who has the most connections in my network?\n",
        "        - Who are the most influential people in my network?\n",
        "        - What is the most common job title in my network?\n",
        "        - What skills clusters exist in my network?\n",
        "\n",
        "        ### Hybrid Queries\n",
        "        - Who are the most influential people at Microsoft in my network?\n",
        "        - Find potential networking opportunities through second-degree connections\n",
        "        - Which industry clusters exist in my network and who are the key people in each?\n",
        "        - Who should I connect with to expand my network in the data science field?\n",
        "\n",
        "        ### Comparison Queries\n",
        "        - Compare Soham's and Emily's networks - who has more tech industry connections?\n",
        "        - Who are the common connections between Soham and Emily?\n",
        "        - Which network has more diverse companies represented?\n",
        "        - Compare the skill distribution between Soham's and Emily's networks\n",
        "        \"\"\")\n",
        "\n",
        "    with gr.Tab(\"About NetworkX AI\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ## About NetworkX AI\n",
        "\n",
        "        NetworkX AI is a powerful tool for professional network analysis, developed to help professionals,\n",
        "        recruiters, and business development teams leverage their LinkedIn connections more effectively.\n",
        "\n",
        "        ### Key Benefits\n",
        "\n",
        "        - **Discover Hidden Insights**: Uncover patterns and relationships in your network that aren't visible through standard LinkedIn interfaces\n",
        "        - **Identify Key Influencers**: Find the most connected and influential people in your network\n",
        "        - **Skill Mapping**: Understand the distribution of skills and expertise across your connections\n",
        "        - **Strategic Networking**: Get recommendations on who to connect with next based on your goals\n",
        "\n",
        "        ### Technology Stack\n",
        "\n",
        "        - **Graph Database**: ArangoDB for efficient storage and querying of network relationships\n",
        "        - **Graph Analytics**: NetworkX for advanced graph algorithms and metrics\n",
        "        - **Natural Language Processing**: LangChain and OpenAI for conversational interface\n",
        "        - **Visualization**: Matplotlib and NetworkX for interactive network visualization\n",
        "\n",
        "        ### Privacy & Security\n",
        "\n",
        "        Your LinkedIn data remains private and is only used for analysis within this application.\n",
        "        No data is shared with third parties or used for any purpose other than providing insights to you.\n",
        "        \"\"\")\n",
        "\n",
        "# Launch the app\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "6LU4k62ywPKs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}