{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "djJR4hmAkr7i",
        "outputId": "85ff5da2-8eb7-4324-fc23-d2b9e915f71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nx-arangodb in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: networkx<=3.4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (3.4)\n",
            "Requirement already satisfied: phenolrs~=0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (0.5.9)\n",
            "Requirement already satisfied: python-arango~=8.1 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (8.1.6)\n",
            "Requirement already satisfied: adbnx-adapter~=5.0.5 in /usr/local/lib/python3.11/dist-packages (from nx-arangodb) (5.0.6)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (2.32.3)\n",
            "Requirement already satisfied: rich>=12.5.1 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (13.9.4)\n",
            "Requirement already satisfied: setuptools>=45 in /usr/local/lib/python3.11/dist-packages (from adbnx-adapter~=5.0.5->nx-arangodb) (75.1.0)\n",
            "Requirement already satisfied: numpy~=1.26 in /usr/local/lib/python3.11/dist-packages (from phenolrs~=0.5->nx-arangodb) (1.26.4)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.3.0)\n",
            "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (1.0.0)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (2.10.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (8.6.1)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from python-arango~=8.1->nx-arangodb) (24.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.7.1->python-arango~=8.1->nx-arangodb) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->adbnx-adapter~=5.0.5->nx-arangodb) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->adbnx-adapter~=5.0.5->nx-arangodb) (0.1.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.8)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.43)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.18)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.55)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.20.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.11)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.1)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install nx-arangodb\n",
        "!pip install --upgrade langchain langchain-community langchain-openai langgraph\n",
        "!pip install pandas matplotlib networkx\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y5SLt-mPk3pr"
      },
      "outputs": [],
      "source": [
        "# Import the required modules\n",
        "import networkx as nx\n",
        "import nx_arangodb as nxadb\n",
        "from arango import ArangoClient\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0WAqzvU9lAoV"
      },
      "outputs": [],
      "source": [
        "# Set OpenAI API key directly\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "5V-TsK-4lAkp",
        "outputId": "aa010e02-8208-445a-c890-82cca9230c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload Soham's LinkedIn connections CSV file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-435b8f1e-9fab-4bc8-b462-c8725af51ed1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-435b8f1e-9fab-4bc8-b462-c8725af51ed1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Connections.csv to Connections (4).csv\n",
            "\n",
            "Upload Emily's LinkedIn connections CSV file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d6992ba8-1ce4-46ef-b0ef-ce839a5205f0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d6992ba8-1ce4-46ef-b0ef-ce839a5205f0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Connections.csv to Connections (5).csv\n",
            "\n",
            "Combined LinkedIn Connections Data:\n",
            "Total connections from Soham: 339\n",
            "Total connections from Emily: 470\n",
            "Total combined connections: 809\n",
            "\n",
            "Sample of combined data:\n",
            "   id          full_name                                     Company  \\\n",
            "0   0      Akash Sonowal                                NoBroker.com   \n",
            "1   1       Sahil Lalani                             Stealth Startup   \n",
            "2   2          Aman Daga                                      PayPal   \n",
            "3   3  Ella Bullock-Papa  Stanford King Center on Global Development   \n",
            "4   4     Jamie Burnette                                 Capital One   \n",
            "\n",
            "                                            Position Email Address  owner  \n",
            "0                                  Data Scientist II                Soham  \n",
            "1                                  Software Engineer                Soham  \n",
            "2          Tech Product Manager - AI Personalization                Soham  \n",
            "3                                 Research Assistant                Soham  \n",
            "4  Business Analyst - Portfolio Strategy & Analyt...                Soham  \n"
          ]
        }
      ],
      "source": [
        "# Function to process LinkedIn connections file\n",
        "def process_connections_file(file_path, owner_name, id_offset=0):\n",
        "    # Load the connections data\n",
        "    connections_df = pd.read_csv(file_path)\n",
        "\n",
        "    # Create a unique identifier for each connection\n",
        "    connections_df['id'] = connections_df.index + id_offset\n",
        "    connections_df['full_name'] = connections_df['First Name'] + ' ' + connections_df['Last Name']\n",
        "    connections_df['owner'] = owner_name  # Add owner information\n",
        "\n",
        "    # Select relevant columns - adjust these based on your actual CSV structure\n",
        "    clean_df = connections_df[['id', 'full_name', 'Company', 'Position', 'Email Address', 'owner']]\n",
        "\n",
        "    # Handle missing values\n",
        "    clean_df = clean_df.fillna({'Company': 'Unknown', 'Position': 'Unknown', 'Email Address': ''})\n",
        "\n",
        "    return clean_df\n",
        "\n",
        "# Upload multiple LinkedIn connections CSV files\n",
        "from google.colab import files\n",
        "print(\"Upload Soham's LinkedIn connections CSV file:\")\n",
        "uploaded_soham = files.upload()  # This will prompt you to upload Soham's connections.csv file\n",
        "\n",
        "print(\"\\nUpload Emily's LinkedIn connections CSV file:\")\n",
        "uploaded_emily = files.upload()  # This will prompt you to upload Emily's connections.csv file\n",
        "\n",
        "# Process each file\n",
        "soham_df = process_connections_file(list(uploaded_soham.keys())[0], \"Soham\", id_offset=0)\n",
        "emily_df = process_connections_file(list(uploaded_emily.keys())[0], \"Emily\", id_offset=10000)\n",
        "\n",
        "# Combine the dataframes\n",
        "combined_df = pd.concat([soham_df, emily_df], ignore_index=True)\n",
        "\n",
        "# Display basic statistics\n",
        "print(\"\\nCombined LinkedIn Connections Data:\")\n",
        "print(f\"Total connections from Soham: {len(soham_df)}\")\n",
        "print(f\"Total connections from Emily: {len(emily_df)}\")\n",
        "print(f\"Total combined connections: {len(combined_df)}\")\n",
        "\n",
        "# Display sample of combined data\n",
        "print(\"\\nSample of combined data:\")\n",
        "print(combined_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNojv0a6lAjb",
        "outputId": "33764f3c-e945-4051-da15-647f0f9e9af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes (connections): 809\n",
            "Number of edges (relationships): 8783\n"
          ]
        }
      ],
      "source": [
        "# Create a NetworkX graph with improved structure and FEWER edges\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes (connections) with attributes\n",
        "for idx, row in combined_df.iterrows():\n",
        "    G.add_node(row['id'],\n",
        "               name=row['full_name'],\n",
        "               company=row['Company'],\n",
        "               position=row['Position'],\n",
        "               email=row['Email Address'],\n",
        "               owner=row['owner'])  # Track whose connection this is\n",
        "\n",
        "# Create a more selective edge creation strategy\n",
        "# 1. For each person, connect to at most 5 random people from the same company\n",
        "companies = combined_df['Company'].unique()\n",
        "for company in companies:\n",
        "    if company != 'Unknown':\n",
        "        same_company = combined_df[combined_df['Company'] == company]['id'].tolist()\n",
        "        # Only create edges if there are multiple people at the company\n",
        "        if len(same_company) > 1:\n",
        "            # For each person, connect to at most 5 others from same company\n",
        "            for person in same_company:\n",
        "                # Get other people at same company\n",
        "                others = [p for p in same_company if p != person]\n",
        "                # Connect to at most 5 random people (or fewer if not enough)\n",
        "                connect_to = min(5, len(others))\n",
        "                if connect_to > 0:\n",
        "                    random_others = random.sample(others, connect_to)\n",
        "                    for other in random_others:\n",
        "                        G.add_edge(person, other, relationship='same_company')\n",
        "\n",
        "# 2. Create a limited number of edges between connections of the same owner\n",
        "# Instead of connecting everyone to everyone, create a more realistic network\n",
        "for owner in [\"Soham\", \"Emily\"]:\n",
        "    owner_connections = combined_df[combined_df['owner'] == owner]['id'].tolist()\n",
        "    # Create a more realistic network structure - each person connects to ~10 others\n",
        "    for person in owner_connections:\n",
        "        others = [p for p in owner_connections if p != person]\n",
        "        # Connect to at most 10 random people (or fewer if not enough)\n",
        "        connect_to = min(10, len(others))\n",
        "        if connect_to > 0:\n",
        "            random_others = random.sample(others, connect_to)\n",
        "            for other in random_others:\n",
        "                if not G.has_edge(person, other):\n",
        "                    G.add_edge(person, other, relationship='same_owner')\n",
        "\n",
        "# Basic graph statistics\n",
        "print(f\"Number of nodes (connections): {G.number_of_nodes()}\")\n",
        "print(f\"Number of edges (relationships): {G.number_of_edges()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8VBqBQtTm_Pj"
      },
      "outputs": [],
      "source": [
        "# Connect to ArangoDB using the provided credentials\n",
        "client = ArangoClient(hosts=\"https://df7687e8971e.arangodb.cloud:8529\")\n",
        "db = client.db(username=\"root\", password=\"1ADDF5Q0eJypkH0QdJNs\", verify=True)\n",
        "\n",
        "# Create collections if they don't exist\n",
        "if not db.has_collection('LinkedIn_node'):\n",
        "    db.create_collection('LinkedIn_node')\n",
        "if not db.has_collection('LinkedIn_node_to_LinkedIn_node'):\n",
        "    db.create_collection('LinkedIn_node_to_LinkedIn_node', edge=True)\n",
        "\n",
        "# Create the graph in ArangoDB\n",
        "if not db.has_graph('LinkedIn'):\n",
        "    graph = db.create_graph('LinkedIn', edge_definitions=[\n",
        "        {\n",
        "            'edge_collection': 'LinkedIn_node_to_LinkedIn_node',\n",
        "            'from_vertex_collections': ['LinkedIn_node'],\n",
        "            'to_vertex_collections': ['LinkedIn_node']\n",
        "        }\n",
        "    ])\n",
        "else:\n",
        "    graph = db.graph('LinkedIn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "byNzvq5IlAQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e86457-76e4-4f93-ba3d-009d7e49d445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleared existing data in ArangoDB\n",
            "Added 100 nodes so far...\n",
            "Added 200 nodes so far...\n",
            "Added 300 nodes so far...\n",
            "Added 400 nodes so far...\n",
            "Error inserting node 10137: [HTTP 400][ERR 600] VPackError error: Expecting digit\n",
            "Added 500 nodes so far...\n",
            "Added 600 nodes so far...\n",
            "Added 700 nodes so far...\n",
            "Added 800 nodes so far...\n",
            "Added 100 edges so far...\n",
            "Added 200 edges so far...\n",
            "Added 300 edges so far...\n",
            "Added 400 edges so far...\n",
            "Added 500 edges so far...\n",
            "Added 600 edges so far...\n",
            "Added 700 edges so far...\n",
            "Added 800 edges so far...\n",
            "Added 900 edges so far...\n",
            "Added 1000 edges so far...\n",
            "Added 1100 edges so far...\n",
            "Added 1200 edges so far...\n",
            "Added 1300 edges so far...\n",
            "Added 1400 edges so far...\n",
            "Added 1500 edges so far...\n",
            "Added 1600 edges so far...\n",
            "Added 1700 edges so far...\n",
            "Added 1800 edges so far...\n",
            "Added 1900 edges so far...\n",
            "Added 2000 edges so far...\n",
            "Added 2100 edges so far...\n",
            "Added 2200 edges so far...\n",
            "Added 2300 edges so far...\n",
            "Added 2400 edges so far...\n",
            "Added 2500 edges so far...\n",
            "Added 2600 edges so far...\n",
            "Added 2700 edges so far...\n",
            "Added 2800 edges so far...\n",
            "Added 2900 edges so far...\n",
            "Added 3000 edges so far...\n",
            "Added 3100 edges so far...\n",
            "Added 3200 edges so far...\n",
            "Added 3300 edges so far...\n",
            "Added 3400 edges so far...\n",
            "Added 3500 edges so far...\n",
            "Added 3600 edges so far...\n",
            "Added 3700 edges so far...\n",
            "Added 3800 edges so far...\n",
            "Added 3900 edges so far...\n",
            "Added 4000 edges so far...\n",
            "Added 4100 edges so far...\n",
            "Added 4200 edges so far...\n",
            "Added 4300 edges so far...\n",
            "Added 4400 edges so far...\n",
            "Added 4500 edges so far...\n",
            "Added 4600 edges so far...\n",
            "Added 4700 edges so far...\n",
            "Added 4800 edges so far...\n",
            "Added 4900 edges so far...\n",
            "Added 5000 edges so far...\n",
            "Added 5100 edges so far...\n",
            "Added 5200 edges so far...\n",
            "Added 5300 edges so far...\n",
            "Added 5400 edges so far...\n",
            "Added 5500 edges so far...\n",
            "Added 5600 edges so far...\n",
            "Added 5700 edges so far...\n",
            "Added 5800 edges so far...\n",
            "Added 5900 edges so far...\n",
            "Added 6000 edges so far...\n",
            "Added 6100 edges so far...\n",
            "Added 6200 edges so far...\n",
            "Added 6300 edges so far...\n",
            "Added 6400 edges so far...\n",
            "Added 6500 edges so far...\n",
            "Added 6600 edges so far...\n",
            "Added 6700 edges so far...\n",
            "Added 6800 edges so far...\n",
            "Added 6900 edges so far...\n",
            "Added 7000 edges so far...\n",
            "Added 7100 edges so far...\n",
            "Added 7200 edges so far...\n",
            "Added 7300 edges so far...\n",
            "Added 7400 edges so far...\n",
            "Added 7500 edges so far...\n",
            "Added 7600 edges so far...\n",
            "Added 7700 edges so far...\n",
            "Added 7800 edges so far...\n",
            "Added 7900 edges so far...\n",
            "Added 8000 edges so far...\n",
            "Added 8100 edges so far...\n",
            "Added 8200 edges so far...\n",
            "Added 8300 edges so far...\n",
            "Added 8400 edges so far...\n",
            "Added 8500 edges so far...\n",
            "Added 8600 edges so far...\n",
            "Added 8700 edges so far...\n",
            "Graph successfully persisted to ArangoDB with 808 nodes and 8783 edges!\n"
          ]
        }
      ],
      "source": [
        "# Clear existing data to avoid conflicts\n",
        "try:\n",
        "    db.collection('LinkedIn_node_to_LinkedIn_node').truncate()\n",
        "    db.collection('LinkedIn_node').truncate()\n",
        "    print(\"Cleared existing data in ArangoDB\")\n",
        "except Exception as e:\n",
        "    print(f\"Error clearing data: {e}\")\n",
        "\n",
        "# Add nodes to ArangoDB with error handling\n",
        "node_count = 0\n",
        "for node_id in G.nodes():\n",
        "    node_data = G.nodes[node_id]\n",
        "    # Create a document key from the node ID\n",
        "    key = str(node_id)\n",
        "\n",
        "    try:\n",
        "        # Add the node to ArangoDB\n",
        "        db.collection('LinkedIn_node').insert({\n",
        "            '_key': key,\n",
        "            'name': node_data.get('name', ''),\n",
        "            'company': node_data.get('company', ''),\n",
        "            'position': node_data.get('position', ''),\n",
        "            'email': node_data.get('email', ''),\n",
        "            'owner': node_data.get('owner', '')\n",
        "        })\n",
        "        node_count += 1\n",
        "\n",
        "        # Print progress every 100 nodes\n",
        "        if node_count % 100 == 0:\n",
        "            print(f\"Added {node_count} nodes so far...\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error inserting node {key}: {e}\")\n",
        "\n",
        "# Add edges to ArangoDB with error handling\n",
        "edge_count = 0\n",
        "for u, v, data in G.edges(data=True):\n",
        "    # Create edge document\n",
        "    edge = {\n",
        "        '_from': f'LinkedIn_node/{u}',\n",
        "        '_to': f'LinkedIn_node/{v}',\n",
        "        'relationship': data.get('relationship', 'connection')\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Add the edge to ArangoDB\n",
        "        db.collection('LinkedIn_node_to_LinkedIn_node').insert(edge)\n",
        "        edge_count += 1\n",
        "\n",
        "        # Print progress every 100 edges\n",
        "        if edge_count % 500 == 0:\n",
        "            print(f\"Added {edge_count} edges so far...\")\n",
        "    except Exception as e:\n",
        "        # Skip duplicate edges\n",
        "        pass\n",
        "\n",
        "print(f\"Graph successfully persisted to ArangoDB with {node_count} nodes and {edge_count} edges!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the graph from ArangoDB for querying\n",
        "G_adb = nx.Graph()\n",
        "\n",
        "# Get all nodes from ArangoDB\n",
        "cursor = db.aql.execute(\n",
        "    \"FOR doc IN LinkedIn_node RETURN doc\"\n",
        ")\n",
        "for node in cursor:\n",
        "    G_adb.add_node(\n",
        "        node['_key'],\n",
        "        name=node.get('name', ''),\n",
        "        company=node.get('company', ''),\n",
        "        position=node.get('position', ''),\n",
        "        email=node.get('email', ''),\n",
        "        owner=node.get('owner', '')\n",
        "    )\n",
        "\n",
        "# Get all edges from ArangoDB\n",
        "cursor = db.aql.execute(\n",
        "    \"FOR edge IN LinkedIn_node_to_LinkedIn_node RETURN edge\"\n",
        ")\n",
        "for edge in cursor:\n",
        "    from_key = edge['_from'].split('/')[1]\n",
        "    to_key = edge['_to'].split('/')[1]\n",
        "    G_adb.add_edge(from_key, to_key, relationship=edge.get('relationship', 'connection'))\n",
        "\n",
        "print(f\"Loaded graph from ArangoDB with {G_adb.number_of_nodes()} nodes and {G_adb.number_of_edges()} edges\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhrWtNS7qiRC",
        "outputId": "0b95e29d-ca01-4b86-fedb-f91385d87fee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded graph from ArangoDB with 809 nodes and 8783 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ArangoGraph object for LangChain\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "arango_graph = ArangoGraph(db)\n",
        "\n",
        "# Initialize the LLM\n",
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "KKWCCVZaqk6l"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tools for the agent\n",
        "from langchain_core.tools import tool\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "import re\n",
        "import networkx as nx\n",
        "\n",
        "@tool\n",
        "def favourite_fruit(query: str):\n",
        "    \"\"\"You are responsible for responding to being asked what your favourite fruit is.\n",
        "    You must say Avocado!\n",
        "    \"\"\"\n",
        "    return \"Avocado!\"\n",
        "\n",
        "@tool\n",
        "def text_to_aql_to_text(query: str):\n",
        "    \"\"\"This tool is available to invoke the\n",
        "    ArangoGraphQAChain object, which enables you to\n",
        "    translate a Natural Language Query into AQL, execute\n",
        "    the query, and translate the result back into Natural Language.\n",
        "    \"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    chain = ArangoGraphQAChain.from_llm(\n",
        "        llm=llm,\n",
        "        graph=arango_graph,\n",
        "        verbose=True,\n",
        "        allow_dangerous_requests=True\n",
        "    )\n",
        "\n",
        "    result = chain.invoke(query)\n",
        "\n",
        "    return str(result[\"result\"])\n",
        "\n",
        "@tool\n",
        "def text_to_nx_algorithm_to_text(query):\n",
        "    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
        "    the ArangoDB Graph. You are responsible for accepting the\n",
        "    Natural Language Query, establishing which algorithm needs to\n",
        "    be executed, executing the algorithm, and translating the results back\n",
        "    to Natural Language, with respect to the original query.\n",
        "\n",
        "    If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n",
        "    this tool.\n",
        "    \"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    print(\"1) Generating NetworkX code\")\n",
        "\n",
        "    text_to_nx = llm.invoke(f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "    Use PageRank algorithm when appropriate for influence or importance analysis.\n",
        "\n",
        "    Only assume that networkx is installed, and other base python dependencies.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Make sure that `FINAL_RESULT` stores a short & concise answer. Avoid setting this variable to a long sequence.\n",
        "\n",
        "    Your code:\n",
        "    \"\"\").content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print(\"2) Executing NetworkX code\")\n",
        "\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    try:\n",
        "        exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        result = local_vars.get(\"FINAL_RESULT\", \"No result produced\")\n",
        "    except Exception as e:\n",
        "        print(f\"EXEC ERROR: {e}\")\n",
        "        return f\"Error in NetworkX analysis: {e}\"\n",
        "\n",
        "    print(\"3) Generating natural language response\")\n",
        "\n",
        "    text_to_nl = llm.invoke(f\"\"\"\n",
        "    I was asked: \"{query}\"\n",
        "\n",
        "    I executed a NetworkX algorithm and got the following result: {result}\n",
        "\n",
        "    Please translate this result into a natural language response that directly answers the original query.\n",
        "    Be concise but informative. Explain any technical terms if necessary.\n",
        "    \"\"\").content\n",
        "\n",
        "    return text_to_nl\n",
        "\n",
        "@tool\n",
        "def hybrid_query_execution(query):\n",
        "    \"\"\"This tool is available to execute hybrid queries that combine AQL and NetworkX algorithms.\n",
        "    It's designed for complex queries that require both data retrieval and graph analytics.\n",
        "    \"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    # Step 1: Plan the hybrid query approach\n",
        "    print(\"Hybrid Query Planning\")\n",
        "\n",
        "    aql_planning = llm.invoke(f\"\"\"\n",
        "    I need to answer this query about a LinkedIn network: \"{query}\"\n",
        "\n",
        "    This requires a hybrid approach using both AQL for data retrieval and NetworkX for graph analytics.\n",
        "\n",
        "    First, I need to determine what data to retrieve with AQL. Write a description of what\n",
        "    data we should retrieve with AQL (don't write the actual AQL yet).\n",
        "\n",
        "    Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    print(\"Hybrid Query Planning - AQL Component:\")\n",
        "    print(aql_planning)\n",
        "\n",
        "    # Step 2: Generate and execute the AQL query\n",
        "    aql_chain = ArangoGraphQAChain.from_llm(\n",
        "        llm=llm,\n",
        "        graph=arango_graph,\n",
        "        verbose=False,\n",
        "        allow_dangerous_requests=True\n",
        "    )\n",
        "\n",
        "    aql_result = aql_chain.invoke(f\"Retrieve the following data: {aql_planning}\")\n",
        "\n",
        "    print(\"\\nAQL Result:\")\n",
        "    print(aql_result[\"result\"])\n",
        "\n",
        "    # Step 3: Generate NetworkX code to analyze the retrieved data\n",
        "    nx_code = llm.invoke(f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have retrieved the following data using AQL: {aql_result[\"result\"]}\n",
        "\n",
        "    Now I need to perform advanced analysis on this data to answer the original query: \"{query}\"\n",
        "\n",
        "    Generate Python code using NetworkX algorithms to analyze this data and answer the query.\n",
        "    Use PageRank algorithm when appropriate for influence or importance analysis.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Your code:\n",
        "    \"\"\").content\n",
        "\n",
        "    nx_code_cleaned = re.sub(r\"^```python\\n|```$\", \"\", nx_code, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print(\"\\nNetworkX Analysis Code:\")\n",
        "    print(nx_code_cleaned)\n",
        "\n",
        "    # Step 4: Execute the NetworkX code\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx, \"aql_data\": aql_result[\"result\"]}\n",
        "    local_vars = {}\n",
        "\n",
        "    try:\n",
        "        exec(nx_code_cleaned, global_vars, local_vars)\n",
        "        nx_result = local_vars.get(\"FINAL_RESULT\", \"No result produced\")\n",
        "    except Exception as e:\n",
        "        print(f\"EXEC ERROR: {e}\")\n",
        "        return f\"Error in NetworkX analysis: {e}\"\n",
        "\n",
        "    # Step 5: Generate the final response\n",
        "    final_response = llm.invoke(f\"\"\"\n",
        "    I was asked: \"{query}\"\n",
        "\n",
        "    First, I retrieved data using AQL: {aql_result[\"result\"]}\n",
        "\n",
        "    Then, I analyzed this data using NetworkX algorithms and got: {nx_result}\n",
        "\n",
        "    Based on both the data retrieval and analysis, provide a comprehensive answer to the original query.\n",
        "    Make sure to explain insights from both the graph structure and the analytics performed.\n",
        "\n",
        "    Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "KwC8kyyAqnKb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatic Query Router\n",
        "def determine_query_type(query):\n",
        "    \"\"\"\n",
        "    Uses LLM to determine the best query type for a given question\n",
        "    \"\"\"\n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "    response = llm.invoke(f\"\"\"\n",
        "    I need to determine the best query type for this question about a LinkedIn network: \"{query}\"\n",
        "\n",
        "    Please classify this query into one of these categories:\n",
        "\n",
        "    1. SIMPLE QUERY: Basic retrieval questions that can be answered with AQL, like \"Who works at Google?\" or \"Find all software engineers\"\n",
        "\n",
        "    2. COMPLEX QUERY: Questions requiring graph algorithms like PageRank, centrality measures, community detection, like \"Who is the most influential person?\" or \"What communities exist in the network?\"\n",
        "\n",
        "    3. HYBRID QUERY: Questions requiring both data retrieval and complex analysis, like \"Who are the most influential people at Microsoft?\" or \"Which second-degree connections should I prioritize meeting?\"\n",
        "\n",
        "    Respond with ONLY ONE of these exact phrases: \"SIMPLE QUERY\", \"COMPLEX QUERY\", or \"HYBRID QUERY\".\n",
        "    \"\"\").content\n",
        "\n",
        "    # Clean up response to get just the classification\n",
        "    response = response.strip().upper()\n",
        "\n",
        "    if \"SIMPLE QUERY\" in response:\n",
        "        return \"Simple Query\", text_to_aql_to_text\n",
        "    elif \"COMPLEX QUERY\" in response:\n",
        "        return \"Complex Query\", text_to_nx_algorithm_to_text\n",
        "    elif \"HYBRID QUERY\" in response:\n",
        "        return \"Hybrid Query\", hybrid_query_execution\n",
        "    else:\n",
        "        return \"Simple Query\", text_to_aql_to_text  # Default to simple query"
      ],
      "metadata": {
        "id": "Cy4DGzVyqpNO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the agent\n",
        "tools = [favourite_fruit, text_to_aql_to_text, text_to_nx_algorithm_to_text, hybrid_query_execution]\n",
        "\n",
        "# Following the template notebook approach for creating the agent\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "def query_graph(query, force_query_type=None):\n",
        "    \"\"\"\n",
        "    Process a query using the appropriate tool based on query type\n",
        "\n",
        "    Parameters:\n",
        "    - query: The user's question\n",
        "    - force_query_type: Optional, to force a specific query type\n",
        "\n",
        "    Returns:\n",
        "    - A tuple containing (result, query_type)\n",
        "    \"\"\"\n",
        "    if force_query_type:\n",
        "        query_type = force_query_type\n",
        "        if query_type == \"Simple Query\":\n",
        "            tool_fn = text_to_aql_to_text\n",
        "        elif query_type == \"Complex Query\":\n",
        "            tool_fn = text_to_nx_algorithm_to_text\n",
        "        elif query_type == \"Hybrid Query\":\n",
        "            tool_fn = hybrid_query_execution\n",
        "        else:\n",
        "            # Default to agent if unknown type\n",
        "            llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "            app = create_react_agent(llm, tools)\n",
        "            final_state = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
        "            return final_state[\"messages\"][-1].content, \"Auto (Agent)\"\n",
        "    else:\n",
        "        # Automatically determine query type\n",
        "        query_type, tool_fn = determine_query_type(query)\n",
        "\n",
        "    # Execute the appropriate tool\n",
        "    if tool_fn:\n",
        "        result = tool_fn(query)\n",
        "        return result, query_type\n",
        "    else:\n",
        "        # Fallback to agent\n",
        "        llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "        app = create_react_agent(llm, tools)\n",
        "        final_state = app.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
        "        return final_state[\"messages\"][-1].content, \"Auto (Agent)\""
      ],
      "metadata": {
        "id": "gv6XMduzqtzJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the agent with a few queries\n",
        "print(\"Query 1: Who in my network works at Google?\")\n",
        "result1, type1 = query_graph(\"Who in my network works at Google?\")\n",
        "print(f\"Query Type: {type1}\")\n",
        "print(result1)\n",
        "\n",
        "print(\"\\nQuery 2: Who has the most connections in my network?\")\n",
        "result2, type2 = query_graph(\"Who has the most connections in my network?\")\n",
        "print(f\"Query Type: {type2}\")\n",
        "print(result2)\n",
        "\n",
        "print(\"\\nQuery 3: Find people in my network who work in the tech industry\")\n",
        "result3, type3 = query_graph(\"Find people in my network who work in the tech industry\")\n",
        "print(f\"Query Type: {type3}\")\n",
        "print(result3)\n",
        "\n",
        "print(\"\\nQuery 4: Who are the most influential people at Microsoft in my network?\")\n",
        "result4, type4 = query_graph(\"Who are the most influential people at Microsoft in my network?\")\n",
        "print(f\"Query Type: {type4}\")\n",
        "print(result4)\n",
        "\n",
        "print(\"\\nQuery 5: Compare Soham's and Emily's networks - who has more tech industry connections?\")\n",
        "result5, type5 = query_graph(\"Compare Soham's and Emily's networks - who has more tech industry connections?\")\n",
        "print(f\"Query Type: {type5}\")\n",
        "print(result5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPXRHsyvqv9Q",
        "outputId": "26df2630-72fb-4f6b-aab7-3cd669ee0aae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query 1: Who in my network works at Google?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-8cef55ae3cb9>:38: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = tool_fn(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
            "WITH LinkedIn_node, LinkedIn_node_to_LinkedIn_node\n",
            "FOR person IN LinkedIn_node\n",
            "  FILTER person.company == \"Google\"\n",
            "  RETURN person\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[{'_key': '161', '_id': 'LinkedIn_node/161', '_rev': '_jV4hbUa---', 'name': 'Kevin Xu', 'company': 'Google', 'position': 'SWE Intern', 'email': '', 'owner': 'Soham'}, {'_key': '219', '_id': 'LinkedIn_node/219', '_rev': '_jV4hecG---', 'name': 'Chely Fernandez', 'company': 'Google', 'position': 'Incoming Software Engineer', 'email': '', 'owner': 'Soham'}, {'_key': '262', '_id': 'LinkedIn_node/262', '_rev': '_jV4hgim---', 'name': 'Aditya Shah', 'company': 'Google', 'position': 'ML Research Engineer', 'email': '', 'owner': 'Soham'}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Type: Simple Query\n",
            "In your LinkedIn network, the following individuals work at Google: Kevin Xu, who is a SWE Intern; Chely Fernandez, who is an Incoming Software Engineer; and Aditya Shah, who is an ML Research Engineer. All of these individuals are associated with the owner, Soham.\n",
            "\n",
            "Query 2: Who has the most connections in my network?\n",
            "1) Generating NetworkX code\n",
            "2) Executing NetworkX code\n",
            "3) Generating natural language response\n",
            "Query Type: Complex Query\n",
            "The person with the most connections in your network is represented by node 119, and they have 38 connections. In network analysis, a \"node\" typically represents an individual or entity, and \"connections\" refer to the links or relationships they have with others in the network.\n",
            "\n",
            "Query 3: Find people in my network who work in the tech industry\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
            "WITH LinkedIn_node, LinkedIn_node_to_LinkedIn_node\n",
            "FOR person IN LinkedIn_node\n",
            "  FILTER person.company == \"Tech Company\" // Assuming \"Tech Company\" is a placeholder for actual tech companies\n",
            "  RETURN person\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Type: Simple Query\n",
            "Summary:\n",
            "\n",
            "There are currently no people in your LinkedIn network who are listed as working in the tech industry.\n",
            "\n",
            "Query 4: Who are the most influential people at Microsoft in my network?\n",
            "Hybrid Query Planning\n",
            "Hybrid Query Planning - AQL Component:\n",
            "To determine the most influential people at Microsoft within your LinkedIn network, we need to retrieve specific data that will allow us to analyze the connections and influence of individuals. Here's a description of the data we should retrieve using AQL:\n",
            "\n",
            "1. **Profile Information**: \n",
            "   - Retrieve basic profile information for each connection in your LinkedIn network, including their current employer, job title, and location. This will help identify which of your connections are currently employed at Microsoft.\n",
            "\n",
            "2. **Connections Data**:\n",
            "   - Retrieve the list of connections for each person in your network. This will help build a graph of your network, where nodes represent individuals and edges represent connections between them.\n",
            "\n",
            "3. **Engagement Metrics**:\n",
            "   - Retrieve engagement metrics such as the number of endorsements, recommendations, and shared content interactions (likes, comments, shares) for each connection. These metrics can help assess the influence of individuals within the network.\n",
            "\n",
            "4. **Professional Experience**:\n",
            "   - Retrieve detailed professional experience for each connection, focusing on their roles and tenure at Microsoft. This will help identify key positions and long-term employees who might have more influence.\n",
            "\n",
            "5. **Skills and Endorsements**:\n",
            "   - Retrieve the list of skills and the number of endorsements for each skill for individuals at Microsoft. This can provide insight into their expertise and influence in specific areas.\n",
            "\n",
            "6. **Groups and Activities**:\n",
            "   - Retrieve information about LinkedIn groups and activities that your connections are involved in, especially those related to Microsoft or relevant industries. Participation in influential groups can be a sign of influence.\n",
            "\n",
            "By gathering this data, we can construct a graph using NetworkX to analyze the network structure and identify the most influential individuals at Microsoft based on their connections, engagement, and professional standing.\n",
            "\n",
            "AQL Result:\n",
            "The query results provide information about two individuals within your LinkedIn network who are currently employed at Microsoft. \n",
            "\n",
            "1. **Nabdeep Shrestha** is a Software Engineer II at Microsoft. His connections include professionals from various companies such as Virginia Tech, Deloitte, Magna International, and Tesla, among others. Notably, one of his connections, Macy So, is also employed at Microsoft as a Technical Program Manager.\n",
            "\n",
            "2. **Macy So** is a Technical Program Manager at Microsoft. Her network includes individuals from companies like Morgan Stanley, Intel Corporation, and OpenAI. She shares a professional connection with Nabdeep Shrestha, indicating a relationship within the same company.\n",
            "\n",
            "These connections provide a diverse network of professionals across different industries, which could be valuable for analyzing influence and engagement within your LinkedIn network, particularly focusing on those associated with Microsoft.\n",
            "\n",
            "NetworkX Analysis Code:\n",
            "import networkx as nx\n",
            "\n",
            "# Create a directed graph\n",
            "G = nx.DiGraph()\n",
            "\n",
            "# Add nodes for Nabdeep Shrestha and Macy So\n",
            "G.add_node('Nabdeep Shrestha', position='Software Engineer II', company='Microsoft')\n",
            "G.add_node('Macy So', position='Technical Program Manager', company='Microsoft')\n",
            "\n",
            "# Add connections for Nabdeep Shrestha\n",
            "connections_nabdeep = [\n",
            "    ('Nabdeep Shrestha', 'Virginia Tech'),\n",
            "    ('Nabdeep Shrestha', 'Deloitte'),\n",
            "    ('Nabdeep Shrestha', 'Magna International'),\n",
            "    ('Nabdeep Shrestha', 'Tesla'),\n",
            "    ('Nabdeep Shrestha', 'Macy So')  # Connection to Macy So\n",
            "]\n",
            "\n",
            "# Add connections for Macy So\n",
            "connections_macy = [\n",
            "    ('Macy So', 'Morgan Stanley'),\n",
            "    ('Macy So', 'Intel Corporation'),\n",
            "    ('Macy So', 'OpenAI'),\n",
            "    ('Macy So', 'Nabdeep Shrestha')  # Connection to Nabdeep Shrestha\n",
            "]\n",
            "\n",
            "# Add edges to the graph\n",
            "G.add_edges_from(connections_nabdeep)\n",
            "G.add_edges_from(connections_macy)\n",
            "\n",
            "# Run PageRank algorithm to determine influence\n",
            "pagerank_scores = nx.pagerank(G)\n",
            "\n",
            "# Filter out only Microsoft employees\n",
            "microsoft_employees = {node: score for node, score in pagerank_scores.items() if G.nodes[node].get('company') == 'Microsoft'}\n",
            "\n",
            "# Sort by PageRank score to find the most influential\n",
            "most_influential = sorted(microsoft_employees.items(), key=lambda x: x[1], reverse=True)\n",
            "\n",
            "# Set the final result\n",
            "FINAL_RESULT = most_influential\n",
            "EXEC ERROR: name 'G' is not defined\n",
            "Query Type: Hybrid Query\n",
            "Error in NetworkX analysis: name 'G' is not defined\n",
            "\n",
            "Query 5: Compare Soham's and Emily's networks - who has more tech industry connections?\n",
            "Hybrid Query Planning\n",
            "Hybrid Query Planning - AQL Component:\n",
            "To compare Soham's and Emily's networks in terms of their tech industry connections, we need to retrieve specific data from the LinkedIn network database using AQL. Here's a description of the data we should retrieve:\n",
            "\n",
            "1. **User Profiles**: Retrieve the profiles of both Soham and Emily to get their unique identifiers. This will help in identifying their respective networks.\n",
            "\n",
            "2. **Connections**: For both Soham and Emily, retrieve their direct connections. This includes the list of user IDs that are directly connected to each of them.\n",
            "\n",
            "3. **Industry Information**: For each connection retrieved in the previous step, obtain the industry information. This will help in filtering out connections that are specifically in the tech industry.\n",
            "\n",
            "4. **Tech Industry Definition**: Define what constitutes the \"tech industry\" within the database. This could be a predefined list of industry categories or tags that are considered part of the tech industry.\n",
            "\n",
            "5. **Connection Details**: Optionally, retrieve additional details about each connection, such as job titles or company names, to provide more context if needed.\n",
            "\n",
            "By retrieving this data, we can then use NetworkX to analyze and compare the number of tech industry connections for both Soham and Emily.\n",
            "\n",
            "AQL Result:\n",
            "The query results indicate that Soham's profile was successfully retrieved, showing that he is associated with the name \"Akash Sonowal\" and works as a Data Scientist II at NoBroker.com. However, there are no direct connections identified for Soham in the tech industry based on the current criteria. On the other hand, Emily's profile could not be found in the database, and consequently, no connections for her were retrieved. This suggests that either Emily does not exist in the database or her profile does not match the search criteria used in the query.\n",
            "\n",
            "NetworkX Analysis Code:\n",
            "import networkx as nx\n",
            "\n",
            "# Create the graph for LinkedIn connections\n",
            "G_linkedin = nx.DiGraph()\n",
            "\n",
            "# Add nodes and edges for Soham\n",
            "G_linkedin.add_node('LinkedIn_node/0', name='Akash Sonowal', company='NoBroker.com', position='Data Scientist II', owner='Soham')\n",
            "# Assuming there are no direct connections for Soham in the tech industry\n",
            "\n",
            "# Add nodes and edges for Emily\n",
            "# Since Emily's profile could not be found, we assume no nodes or edges for Emily\n",
            "\n",
            "# Calculate PageRank for influence analysis\n",
            "pagerank_scores = nx.pagerank(G_linkedin)\n",
            "\n",
            "# Determine the number of connections in the tech industry\n",
            "soham_connections = len([node for node, data in G_linkedin.nodes(data=True) if data.get('owner') == 'Soham'])\n",
            "emily_connections = 0  # Since Emily's profile could not be found\n",
            "\n",
            "# Compare the number of connections\n",
            "if soham_connections > emily_connections:\n",
            "    FINAL_RESULT = \"Soham has more tech industry connections.\"\n",
            "elif emily_connections > soham_connections:\n",
            "    FINAL_RESULT = \"Emily has more tech industry connections.\"\n",
            "else:\n",
            "    FINAL_RESULT = \"Soham and Emily have the same number of tech industry connections.\"\n",
            "\n",
            "FINAL_RESULT\n",
            "Query Type: Hybrid Query\n",
            "Based on the data retrieval and analysis conducted, we can provide a comprehensive answer to the query regarding the comparison of Soham's and Emily's networks in terms of tech industry connections.\n",
            "\n",
            "### Data Retrieval Insights:\n",
            "\n",
            "1. **Soham's Profile:**\n",
            "   - Soham's profile was successfully retrieved from the database. He is identified as \"Akash Sonowal\" and works as a Data Scientist II at NoBroker.com.\n",
            "   - The initial data retrieval did not identify any direct connections for Soham in the tech industry based on the criteria used.\n",
            "\n",
            "2. **Emily's Profile:**\n",
            "   - Emily's profile could not be found in the database. This could mean that Emily either does not exist in the database or her profile does not match the search criteria used in the query.\n",
            "   - Consequently, no connections for Emily were retrieved.\n",
            "\n",
            "### Network Analysis Insights:\n",
            "\n",
            "Using NetworkX algorithms, further analysis was conducted on the available data:\n",
            "\n",
            "- **Soham's Network:**\n",
            "  - Despite the initial data retrieval indicating no direct tech industry connections, the NetworkX analysis suggests that Soham has more tech industry connections. This discrepancy could be due to indirect connections or network effects that were not captured in the initial query.\n",
            "  - NetworkX algorithms might have identified connections through secondary or tertiary links, indicating that Soham is part of a broader tech industry network, even if not directly connected.\n",
            "\n",
            "- **Emily's Network:**\n",
            "  - Since Emily's profile was not found, no network analysis could be performed for her. Therefore, she has no recorded tech industry connections in this context.\n",
            "\n",
            "### Conclusion:\n",
            "\n",
            "Based on both the data retrieval and the network analysis, Soham has more tech industry connections than Emily. The initial lack of direct connections for Soham was addressed by the NetworkX analysis, which revealed a more complex network structure, possibly through indirect connections. Emily's absence from the database means she has no recorded connections, leading to the conclusion that Soham has a more extensive network in the tech industry.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import base64\n",
        "from PIL import Image\n",
        "\n",
        "# Function to create a simplified network visualization\n",
        "def create_network_visualization(owner_filter=None, company_filter=None, limit=100):\n",
        "    # Filter graph based on parameters\n",
        "    if owner_filter and owner_filter != \"All\":\n",
        "        nodes = [n for n, attr in G_adb.nodes(data=True) if attr.get('owner') == owner_filter]\n",
        "        filtered_graph = G_adb.subgraph(nodes)\n",
        "    else:\n",
        "        filtered_graph = G_adb\n",
        "\n",
        "    if company_filter and company_filter != \"All Companies\":\n",
        "        nodes = [n for n, attr in filtered_graph.nodes(data=True) if attr.get('company') == company_filter]\n",
        "        filtered_graph = filtered_graph.subgraph(nodes)\n",
        "\n",
        "    # If graph is too large, take a sample\n",
        "    if filtered_graph.number_of_nodes() > limit:\n",
        "        # Get top nodes by degree centrality\n",
        "        centrality = nx.degree_centrality(filtered_graph)\n",
        "        top_nodes = sorted(centrality, key=centrality.get, reverse=True)[:limit]\n",
        "        filtered_graph = filtered_graph.subgraph(top_nodes)\n",
        "\n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Use a more efficient layout algorithm\n",
        "    pos = nx.spring_layout(filtered_graph, k=0.3, iterations=50, seed=42)\n",
        "\n",
        "    # Color nodes by owner\n",
        "    node_colors = []\n",
        "    for node in filtered_graph.nodes():\n",
        "        owner = filtered_graph.nodes[node].get('owner', '')\n",
        "        if owner == \"Soham\":\n",
        "            node_colors.append(\"#4285F4\")  # Blue for Soham\n",
        "        elif owner == \"Emily\":\n",
        "            node_colors.append(\"#EA4335\")  # Red for Emily\n",
        "        else:\n",
        "            node_colors.append(\"#FBBC05\")  # Yellow for unknown\n",
        "\n",
        "    # Draw nodes with simpler styling\n",
        "    nx.draw_networkx_nodes(filtered_graph, pos, node_size=100, node_color=node_colors, alpha=0.8)\n",
        "\n",
        "    # Draw edges with simple styling\n",
        "    nx.draw_networkx_edges(filtered_graph, pos, alpha=0.3, width=0.5)\n",
        "\n",
        "    # Draw labels for only a subset of nodes to avoid clutter\n",
        "    if filtered_graph.number_of_nodes() > 30:\n",
        "        # Get top nodes by degree\n",
        "        degree_dict = dict(filtered_graph.degree())\n",
        "        top_nodes = sorted(degree_dict, key=degree_dict.get, reverse=True)[:30]\n",
        "        labels = {node: filtered_graph.nodes[node].get('name', '') for node in top_nodes}\n",
        "    else:\n",
        "        labels = {node: filtered_graph.nodes[node].get('name', '') for node in filtered_graph.nodes()}\n",
        "\n",
        "    nx.draw_networkx_labels(filtered_graph, pos, labels=labels, font_size=8, font_weight='bold')\n",
        "\n",
        "    title = \"LinkedIn Network Graph\"\n",
        "    if owner_filter and owner_filter != \"All\":\n",
        "        title += f\" - {owner_filter}'s Connections\"\n",
        "    if company_filter and company_filter != \"All Companies\":\n",
        "        title += f\" at {company_filter}\"\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save to a BytesIO object\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=300)\n",
        "    buf.seek(0)\n",
        "    plt.close()\n",
        "\n",
        "    return Image.open(buf)\n",
        "\n",
        "# Function to get network statistics\n",
        "def get_network_stats(owner_filter=None):\n",
        "    # Filter graph by owner if specified\n",
        "    if owner_filter and owner_filter != \"All\":\n",
        "        owner_nodes = [n for n, attr in G_adb.nodes(data=True) if attr.get('owner') == owner_filter]\n",
        "        filtered_graph = G_adb.subgraph(owner_nodes)\n",
        "    else:\n",
        "        filtered_graph = G_adb\n",
        "\n",
        "    # Calculate PageRank\n",
        "    pagerank = nx.pagerank(filtered_graph)\n",
        "\n",
        "    # Get top influential people\n",
        "    top_influential = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "    top_influential_names = [(filtered_graph.nodes[node].get('name', ''), score)\n",
        "                            for node, score in top_influential]\n",
        "\n",
        "    # Basic statistics\n",
        "    stats = {\n",
        "        \"Total Connections\": filtered_graph.number_of_nodes(),\n",
        "        \"Total Relationships\": filtered_graph.number_of_edges(),\n",
        "        \"Network Density\": nx.density(filtered_graph),\n",
        "        \"Average Clustering\": nx.average_clustering(filtered_graph),\n",
        "    }\n",
        "\n",
        "    # Get top companies\n",
        "    companies = {}\n",
        "    for node in filtered_graph.nodes():\n",
        "        company = filtered_graph.nodes[node].get('company', 'Unknown')\n",
        "        if company != 'Unknown':\n",
        "            companies[company] = companies.get(company, 0) + 1\n",
        "\n",
        "    top_companies = sorted(companies.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "    # Format the output\n",
        "    output = \"## Network Statistics\\n\\n\"\n",
        "    for key, value in stats.items():\n",
        "        output += f\"**{key}:** {value:.4f}\\n\" if isinstance(value, float) else f\"**{key}:** {value}\\n\"\n",
        "\n",
        "    output += \"\\n## Most Influential People (PageRank)\\n\\n\"\n",
        "    for name, score in top_influential_names:\n",
        "        output += f\"- **{name}:** {score:.4f}\\n\"\n",
        "\n",
        "    output += \"\\n## Top Companies in Your Network\\n\\n\"\n",
        "    for company, count in top_companies:\n",
        "        output += f\"- **{company}:** {count} connections\\n\"\n",
        "\n",
        "    return output\n",
        "\n",
        "# Function to get list of companies\n",
        "def get_company_list():\n",
        "    companies = set()\n",
        "    for node in G_adb.nodes():\n",
        "        company = G_adb.nodes[node].get('company', '')\n",
        "        if company and company != 'Unknown':\n",
        "            companies.add(company)\n",
        "\n",
        "    return [\"All Companies\"] + sorted(list(companies))\n",
        "\n",
        "# Function to process queries with automatic routing\n",
        "def process_query_with_routing(query):\n",
        "    if not query.strip():\n",
        "        return \"Please enter a query.\"\n",
        "\n",
        "    result, query_type = query_graph(query)\n",
        "\n",
        "    # Format the response with query type information\n",
        "    response = f\"**Query Type:** {query_type}\\n\\n{result}\"\n",
        "    return response\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks(title=\"LinkedIn Network Analyzer\") as demo:\n",
        "    gr.Markdown(\"# LinkedIn Network Analyzer\")\n",
        "    gr.Markdown(\"Ask questions about your combined LinkedIn networks and get insights using advanced graph analytics.\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Query Network\"):\n",
        "            query_input = gr.Textbox(\n",
        "                label=\"Ask a question about your LinkedIn network\",\n",
        "                placeholder=\"e.g., Who are the most influential people at Google in my network?\",\n",
        "                lines=3\n",
        "            )\n",
        "            query_button = gr.Button(\"Submit Query\")\n",
        "            query_output = gr.Markdown()\n",
        "\n",
        "            query_button.click(\n",
        "                process_query_with_routing,\n",
        "                inputs=query_input,\n",
        "                outputs=query_output\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Network Visualization\"):\n",
        "            with gr.Row():\n",
        "                viz_owner_filter = gr.Radio(\n",
        "                    [\"All\", \"Soham\", \"Emily\"],\n",
        "                    label=\"Filter by network owner\",\n",
        "                    value=\"All\"\n",
        "                )\n",
        "                viz_company_filter = gr.Dropdown(\n",
        "                    choices=get_company_list(),\n",
        "                    label=\"Filter by company\",\n",
        "                    value=\"All Companies\"\n",
        "                )\n",
        "\n",
        "            viz_button = gr.Button(\"Generate Network Visualization\")\n",
        "            viz_output = gr.Image(type=\"pil\")\n",
        "\n",
        "            viz_button.click(\n",
        "                create_network_visualization,\n",
        "                inputs=[viz_owner_filter, viz_company_filter],\n",
        "                outputs=viz_output\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Network Statistics\"):\n",
        "            with gr.Row():\n",
        "                stats_owner_filter = gr.Radio(\n",
        "                    [\"All\", \"Soham\", \"Emily\"],\n",
        "                    label=\"Filter by network owner\",\n",
        "                    value=\"All\"\n",
        "                )\n",
        "                stats_button = gr.Button(\"Generate Network Statistics\")\n",
        "\n",
        "            stats_output = gr.Markdown()\n",
        "\n",
        "            stats_button.click(\n",
        "                get_network_stats,\n",
        "                inputs=stats_owner_filter,\n",
        "                outputs=stats_output\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Sample Queries\"):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ## Sample Queries to Try\n",
        "\n",
        "            ### Simple Queries\n",
        "            - Who in my network works at Google?\n",
        "            - Find all connections who are software engineers\n",
        "            - Which companies have the most people in my network?\n",
        "\n",
        "            ### Complex Queries (Using PageRank and other algorithms)\n",
        "            - Who has the most connections in my network?\n",
        "            - Who are the most influential people in my network?\n",
        "            - What is the most common job title in my network?\n",
        "\n",
        "            ### Hybrid Queries\n",
        "            - Who are the most influential people at Microsoft in my network?\n",
        "            - Find potential networking opportunities through second-degree connections\n",
        "            - Which industry clusters exist in my network and who are the key people in each?\n",
        "\n",
        "            ### Comparison Queries\n",
        "            - Compare Soham's and Emily's networks - who has more tech industry connections?\n",
        "            - Who are the common connections between Soham and Emily?\n",
        "            - Which network has more diverse companies represented?\n",
        "            \"\"\")\n",
        "\n",
        "# Launch the app\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "igKPIQDirGb6",
        "outputId": "f0cfeea5-ba99-4786-b2a9-1f873980971e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f22d82c6d80ddf712f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f22d82c6d80ddf712f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}